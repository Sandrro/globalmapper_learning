{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS: zones=EPSG:32636, points=EPSG:32636\n",
      "Counts: zones=3, points=6678\n",
      "[zone 63] cells_in=3383, pos_cells=3290, density[min,max]=(0, 0.1549)\n",
      "[zone 65] cells_in=3515, pos_cells=3150, density[min,max]=(0, 0.2401)\n",
      "[zone 68] cells_in=3515, pos_cells=3497, density[min,max]=(0, 0.1102)\n",
      "Готово: /root/globalmapper_learning/out_2/isolines.geojson | изолиний: 365\n",
      "GRID=15.0 м, BANDWIDTH=10.0 м, уровни=[0.6, 0.75, 0.85, 0.92, 0.97], USE_E_WEIGHTS=True\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Изолинии плотности по точкам, вписанные в контуры квартала (без утечек за границу)\n",
    "# Пути берем из вашего скрипта:\n",
    "#   zones  -> /root/globalmapper_learning/zones.geojson\n",
    "#   points -> /root/globalmapper_learning/out_2/blocks_infer_centroids.geojson\n",
    "# Дефолтная СК: EPSG:32636 (метры).\n",
    "#\n",
    "# Как отключить влияние 'e':\n",
    "#   1) Поставьте USE_E_WEIGHTS = False  (веса = 1 для всех точек), ИЛИ\n",
    "#   2) Укажите WEIGHT_COLUMN = None.\n",
    "#\n",
    "# Требуется: geopandas, shapely, numpy, pandas, scikit-image, scipy\n",
    "\n",
    "# !pip install geopandas shapely pyproj numpy pandas scikit-image scipy --quiet\n",
    "\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.prepared import prep\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "# ---------------------\n",
    "# Параметры\n",
    "# ---------------------\n",
    "PATH_ZONES  = Path(\"/root/globalmapper_learning/zones.geojson\")\n",
    "PATH_POINTS = Path(\"/root/globalmapper_learning/out_2/infer_centroids.geojson\")\n",
    "OUT_PATH    = Path(\"/root/globalmapper_learning/out_2/isolines.geojson\")\n",
    "\n",
    "CRS_EPSG        = 32636\n",
    "GRID_SIZE_M     = 15.0          # шаг растра, м\n",
    "BANDWIDTH_M     = 10.0          # σ Гаусса, м\n",
    "LEVEL_QUANTILES = [0.60, 0.75, 0.85, 0.92, 0.97]\n",
    "MIN_LINE_LEN_M  = 2 * GRID_SIZE_M\n",
    "MAX_LEVELS      = 12\n",
    "\n",
    "# Управление весами 'e'\n",
    "USE_E_WEIGHTS   = True          # ← поставьте False, чтобы полностью убрать влияние e\n",
    "WEIGHT_COLUMN   = None          # если хотите явно указать колонку веса, например \"e\"; None = авто-поиск\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------\n",
    "# Утилиты\n",
    "# ---------------------\n",
    "def ensure_epsg_32636(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Работаем в EPSG:32636: если crs отсутствует — назначаем, если иная — перепроецируем.\"\"\"\n",
    "    if gdf.crs is None:\n",
    "        return gdf.set_crs(epsg=CRS_EPSG, allow_override=True)\n",
    "    if gdf.crs.to_epsg() != CRS_EPSG:\n",
    "        return gdf.to_crs(epsg=CRS_EPSG)\n",
    "    return gdf\n",
    "\n",
    "def extract_weights(gdf_pts: gpd.GeoDataFrame, use_e: bool = True, weight_col: Optional[str] = None) -> np.ndarray:\n",
    "    \"\"\"Вернуть веса точек. Если use_e=False → все единицы. Иначе — берем колонку 'e' (или заданную), нормируем в [1,2].\"\"\"\n",
    "    if not use_e:\n",
    "        return np.ones(len(gdf_pts), dtype=float)\n",
    "    col = weight_col\n",
    "    if col is None:\n",
    "        for c in [\"e\",\"e_i\",\"E\",\"e_pred\",\"existence\",\"existence_score\"]:\n",
    "            if c in gdf_pts.columns:\n",
    "                col = c\n",
    "                break\n",
    "    if col is None:\n",
    "        return np.ones(len(gdf_pts), dtype=float)\n",
    "    w = pd.to_numeric(gdf_pts[col], errors=\"coerce\").fillna(0.0).to_numpy(dtype=float)\n",
    "    if w.size:\n",
    "        w_min, w_max = np.nanmin(w), np.nanmax(w)\n",
    "        if w_max > w_min:\n",
    "            w = (w - w_min) / (w_max - w_min)\n",
    "        w = np.clip(w, 0.0, 1.0)\n",
    "        w = 1.0 + w  # итог 1..2\n",
    "    else:\n",
    "        w = np.ones(len(gdf_pts), dtype=float)\n",
    "    return w\n",
    "\n",
    "def cell_centers_mask(poly, xedges, yedges):\n",
    "    xs = (xedges[:-1] + xedges[1:]) * 0.5\n",
    "    ys = (yedges[:-1] + yedges[1:]) * 0.5\n",
    "    XX, YY = np.meshgrid(xs, ys)  # H x W\n",
    "    centers = np.column_stack([XX.ravel(), YY.ravel()])\n",
    "    m = np.fromiter((poly.covers(Point(xy)) for xy in centers), dtype=bool).reshape(len(ys), len(xs))\n",
    "    return m\n",
    "\n",
    "def density_grid_for_block(poly, px, py, pw, grid_m: float, bandwidth_m: float):\n",
    "    \"\"\"\n",
    "    Растр внутри квартала с корректным поведением у границ:\n",
    "      1) В гистограмму попадают только точки, которые действительно лежат в квартале.\n",
    "      2) Сглаживание Гауссом нормируется на «маску внутри» (edge correction), чтобы не занижать у границ.\n",
    "      Возврат: (density HxW, xedges, yedges, inside_mask)\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = poly.bounds\n",
    "    W = max(3, int(math.ceil((maxx - minx) / grid_m)))\n",
    "    H = max(3, int(math.ceil((maxy - miny) / grid_m)))\n",
    "\n",
    "    # Регулярная сетка по bbox (геометрия нужна для покрытия именно полигона)\n",
    "    xedges = np.linspace(minx, maxx, W+1)\n",
    "    yedges = np.linspace(miny, maxy, H+1)\n",
    "\n",
    "    # Маска ячеек строго внутри полигона\n",
    "    inside_mask = cell_centers_mask(poly, xedges, yedges)\n",
    "\n",
    "    # Точки: сначала bbox-фильтр, затем точная проверка внутри полигона\n",
    "    pr = prep(poly)\n",
    "    in_bbox = (px >= minx) & (px <= maxx) & (py >= miny) & (py <= maxy)\n",
    "    if np.any(in_bbox):\n",
    "        sel = np.fromiter((pr.covers(Point(x, y)) for x, y in zip(px[in_bbox], py[in_bbox])), dtype=bool)\n",
    "        px_in = px[in_bbox][sel]\n",
    "        py_in = py[in_bbox][sel]\n",
    "        pw_in = pw[in_bbox][sel]\n",
    "    else:\n",
    "        px_in = py_in = pw_in = np.array([], dtype=float)\n",
    "\n",
    "    # 2D-гистограмма ТОЛЬКО по точкам внутри квартала\n",
    "    hist, _, _ = np.histogram2d(\n",
    "        px_in, py_in,\n",
    "        bins=[W, H],\n",
    "        range=[[minx, maxx], [miny, maxy]],\n",
    "        weights=pw_in\n",
    "    )\n",
    "    counts = hist.T  # H x W\n",
    "\n",
    "    # Гауссово сглаживание + edge correction (делим на сглаженную маску внутри)\n",
    "    sigma_cells = max(0.5, float(bandwidth_m / grid_m))\n",
    "    smooth_counts = gaussian_filter(counts, sigma=sigma_cells, mode=\"nearest\")\n",
    "    smooth_mask   = gaussian_filter(inside_mask.astype(float), sigma=sigma_cells, mode=\"nearest\")\n",
    "    smooth_mask   = np.maximum(smooth_mask, 1e-9)  # защита от деления на 0\n",
    "    smooth_corr   = smooth_counts / smooth_mask\n",
    "\n",
    "    # Плотность (ед./м²); вне полигона ставим чуть ниже минимума внутри\n",
    "    cell_area = grid_m * grid_m\n",
    "    density = smooth_corr / max(cell_area, 1.0)\n",
    "    vals_in = density[inside_mask]\n",
    "    if vals_in.size:\n",
    "        min_in = float(vals_in.min())\n",
    "        density = np.where(inside_mask, density, min_in - 1e-9)\n",
    "    else:\n",
    "        density = np.where(inside_mask, density, -np.inf)\n",
    "\n",
    "    return density, xedges, yedges, inside_mask\n",
    "\n",
    "def build_levels_from_quantiles(vals: np.ndarray, quantiles: List[float]) -> List[float]:\n",
    "    vals = np.asarray(vals)\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    if vals.size == 0:\n",
    "        return []\n",
    "    vmin, vmax = float(vals.min()), float(vals.max())\n",
    "    if not np.isfinite(vmin) or not np.isfinite(vmax) or vmin == vmax:\n",
    "        return []\n",
    "    lvl_list = []\n",
    "    for q in quantiles:\n",
    "        q = float(np.clip(q, 0.0, 1.0))\n",
    "        lvl = float(np.quantile(vals, q))\n",
    "        if vmin < lvl < vmax and (not lvl_list or abs(lvl - lvl_list[-1]) > 1e-12):\n",
    "            lvl_list.append(lvl)\n",
    "    if len(lvl_list) == 0:\n",
    "        lvl_list = list(np.linspace(vmin + 1e-9, vmax - 1e-9, 5))\n",
    "    if len(lvl_list) > MAX_LEVELS:\n",
    "        step = max(1, len(lvl_list)//MAX_LEVELS)\n",
    "        lvl_list = lvl_list[::step][:MAX_LEVELS]\n",
    "    return lvl_list\n",
    "\n",
    "def contours_for_levels(density, xedges, yedges, levels, min_len_m):\n",
    "    lines = []\n",
    "    dx = (xedges[1] - xedges[0])\n",
    "    dy = (yedges[1] - yedges[0])\n",
    "    def ij_to_xy(ii, jj):\n",
    "        x = xedges[0] + jj * dx\n",
    "        y = yedges[0] + ii * dy\n",
    "        return x, y\n",
    "    for lvl in levels:\n",
    "        try:\n",
    "            paths = find_contours(density, level=lvl)\n",
    "        except Exception:\n",
    "            continue\n",
    "        for path in paths:\n",
    "            if len(path) < 2:\n",
    "                continue\n",
    "            coords = [ij_to_xy(i, j) for (i, j) in path]\n",
    "            geom = LineString(coords)\n",
    "            if geom.is_valid and geom.length >= min_len_m:\n",
    "                lines.append((geom, lvl))\n",
    "    return lines\n",
    "\n",
    "# ---------------------\n",
    "# Загрузка данных и CRS\n",
    "# ---------------------\n",
    "gdf_z = gpd.read_file(PATH_ZONES)\n",
    "gdf_p = gpd.read_file(PATH_POINTS)\n",
    "\n",
    "# Точки и веса (уберите влияние e: USE_E_WEIGHTS=False или WEIGHT_COLUMN=None)\n",
    "px = gdf_p.geometry.x.to_numpy()\n",
    "py = gdf_p.geometry.y.to_numpy()\n",
    "pw = extract_weights(gdf_p, use_e=USE_E_WEIGHTS, weight_col=WEIGHT_COLUMN)\n",
    "\n",
    "print(f\"CRS: zones={gdf_z.crs}, points={gdf_p.crs}\")\n",
    "print(f\"Counts: zones={len(gdf_z)}, points={len(gdf_p)}\")\n",
    "\n",
    "# ---------------------\n",
    "# Основной цикл по кварталам\n",
    "# ---------------------\n",
    "out_records = []\n",
    "zone_id_col = next((c for c in [\"id\",\"zone_id\",\"ZONE_ID\",\"zone\",\"name\"] if c in gdf_z.columns), None)\n",
    "\n",
    "for idx, row in gdf_z.iterrows():\n",
    "    poly = row.geometry\n",
    "    if poly is None or poly.is_empty:\n",
    "        continue\n",
    "    zid = row.get(zone_id_col, idx) if zone_id_col else idx\n",
    "\n",
    "    density, xedges, yedges, inside_mask = density_grid_for_block(poly, px, py, pw, GRID_SIZE_M, BANDWIDTH_M)\n",
    "\n",
    "    vals_in = density[inside_mask]\n",
    "    finite_pos = vals_in[np.isfinite(vals_in) & (vals_in > 0)]\n",
    "    print(f\"[zone {zid}] cells_in={inside_mask.sum()}, pos_cells={finite_pos.size}, \"\n",
    "          f\"density[min,max]=({np.nanmin(vals_in):.4g}, {np.nanmax(vals_in):.4g})\")\n",
    "\n",
    "    levels = build_levels_from_quantiles(finite_pos, LEVEL_QUANTILES)\n",
    "    if not levels:\n",
    "        vmn, vmx = float(np.nanmin(vals_in)), float(np.nanmax(vals_in))\n",
    "        if np.isfinite(vmn) and np.isfinite(vmx) and vmn < vmx:\n",
    "            levels = [vmn + 0.5*(vmx - vmn)]\n",
    "        else:\n",
    "            print(f\"  [skip] нет валидного диапазона плотности для изолиний\")\n",
    "            continue\n",
    "\n",
    "    lines = contours_for_levels(density, xedges, yedges, levels, MIN_LINE_LEN_M)\n",
    "    if not lines and finite_pos.size:\n",
    "        a, b = np.quantile(finite_pos, 0.05), np.quantile(finite_pos, 0.95)\n",
    "        if a < b:\n",
    "            tight_levels = list(np.linspace(a + 1e-9, b - 1e-9, min(5, MAX_LEVELS)))\n",
    "            lines = contours_for_levels(density, xedges, yedges, tight_levels, MIN_LINE_LEN_M)\n",
    "\n",
    "    for geom, lvl in lines:\n",
    "        inter = geom.intersection(poly)\n",
    "        if inter.is_empty:\n",
    "            continue\n",
    "        if inter.geom_type == \"LineString\":\n",
    "            geoms = [inter]\n",
    "        elif inter.geom_type == \"MultiLineString\":\n",
    "            geoms = list(inter.geoms)\n",
    "        else:\n",
    "            continue\n",
    "        for g in geoms:\n",
    "            if g.length >= MIN_LINE_LEN_M:\n",
    "                out_records.append({\n",
    "                    \"zone_id\": zid,\n",
    "                    \"level\": float(lvl),\n",
    "                    \"grid_m\": float(GRID_SIZE_M),\n",
    "                    \"bandwidth_m\": float(BANDWIDTH_M),\n",
    "                    \"use_e\": bool(USE_E_WEIGHTS),\n",
    "                    \"geometry\": g\n",
    "                })\n",
    "\n",
    "# ---------------------\n",
    "# Сохранение\n",
    "# ---------------------\n",
    "if out_records:\n",
    "    gdf_out = gpd.GeoDataFrame(out_records, geometry=\"geometry\", crs=gdf_z.crs)\n",
    "else:\n",
    "    gdf_out = gpd.GeoDataFrame(\n",
    "        {\"zone_id\": pd.Series(dtype=\"int64\"),\n",
    "         \"level\": pd.Series(dtype=\"float64\"),\n",
    "         \"grid_m\": pd.Series(dtype=\"float64\"),\n",
    "         \"bandwidth_m\": pd.Series(dtype=\"float64\"),\n",
    "         \"use_e\": pd.Series(dtype=\"bool\"),\n",
    "         \"geometry\": gpd.GeoSeries(dtype=\"geometry\")},\n",
    "        geometry=\"geometry\",\n",
    "        crs=gdf_z.crs\n",
    "    )\n",
    "\n",
    "gdf_out_wgs = gdf_out.to_crs(4326)\n",
    "gdf_out_wgs.to_file(OUT_PATH, driver=\"GeoJSON\")\n",
    "print(f\"Готово: {OUT_PATH} | изолиний: {len(gdf_out_wgs)}\")\n",
    "print(f\"GRID={GRID_SIZE_M} м, BANDWIDTH={BANDWIDTH_M} м, уровни={LEVEL_QUANTILES}, USE_E_WEIGHTS={USE_E_WEIGHTS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1800/2323380855.py:212: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  grid[\"iso_level_raw\"].replace(-1, np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK → /root/globalmapper_learning/out_2/buildings_clustered_tagged_rings.geojson \n",
      " Всего клеток: 10065, raw True: 5439, closed True: 5613\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Клетки под изолиниями + правило \"3 стороны\" + уровень кольца\n",
    "# Входные пути берём как в вашем ноутбуке.\n",
    "\n",
    "# %%\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString, MultiLineString\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# --- ПАРАМЕТРЫ/ПУТИ ---\n",
    "PATH_ZONES   = Path(\"/root/globalmapper_learning/zones.geojson\")  # пока не используем\n",
    "PATH_ISOLINE = Path(\"/root/globalmapper_learning/out_2/isolines.geojson\")\n",
    "PATH_GRID    = Path(\"/root/globalmapper_learning/out_2/buildings_clustered.geojson\")\n",
    "\n",
    "# В этой среде можно автоматически взять загруженные файлы\n",
    "if Path(\"/mnt/data/isolines.geojson\").exists():\n",
    "    PATH_ISOLINE = Path(\"/mnt/data/isolines.geojson\")\n",
    "if Path(\"/mnt/data/buildings_clustered.geojson\").exists():\n",
    "    PATH_GRID    = Path(\"/mnt/data/buildings_clustered.geojson\")\n",
    "\n",
    "# Изолинии-ЛИНИИ буферим до полос (в метрах)\n",
    "ISO_BUFFER_M = 1.0\n",
    "\n",
    "# Порог для распознавания \"сосед по стороне\", доля от характерной длины ребра клетки\n",
    "EDGE_SHARE_FRAC = 0.2  # 20% длины ребра (для 15 м → ~3 м)\n",
    "\n",
    "OUT_TAGGED = PATH_GRID.with_name(f\"{PATH_GRID.stem}_tagged_rings.geojson\")\n",
    "\n",
    "# --- ВСПОМОГАТЕЛЬНОЕ ---\n",
    "def to_metric_crs(gdf: gpd.GeoDataFrame, fallback_epsg: int = 32636) -> gpd.GeoDataFrame:\n",
    "    if gdf.crs is None:\n",
    "        warnings.warn(f\"CRS отсутствует, предполагаю EPSG:{fallback_epsg}\")\n",
    "        return gdf.set_crs(epsg=fallback_epsg, allow_override=True)\n",
    "    if getattr(gdf.crs, \"is_projected\", None) is True:\n",
    "        return gdf\n",
    "    warnings.warn(f\"CRS не метрический ({gdf.crs}), проецирую в EPSG:{fallback_epsg}\")\n",
    "    return gdf.to_crs(epsg=fallback_epsg)\n",
    "\n",
    "def isolines_to_polys(iso_gdf: gpd.GeoDataFrame, buffer_m: float) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Линии → полосы через buffer; полигоны оставляем как есть. Возвращает GeoDataFrame с индексом iso_pid.\"\"\"\n",
    "    iso_gdf = iso_gdf.copy()\n",
    "    line_mask = iso_gdf.geom_type.isin([\"LineString\", \"MultiLineString\"])\n",
    "    poly_mask = iso_gdf.geom_type.isin([\"Polygon\", \"MultiPolygon\"])\n",
    "\n",
    "    parts = []\n",
    "    if line_mask.any():\n",
    "        lines = iso_gdf.loc[line_mask].copy()\n",
    "        lines[\"geometry\"] = lines.geometry.buffer(buffer_m)\n",
    "        parts.append(lines)\n",
    "    if poly_mask.any():\n",
    "        parts.append(iso_gdf.loc[poly_mask].copy())\n",
    "\n",
    "    out = pd.concat(parts, ignore_index=True) if parts else iso_gdf.copy()\n",
    "    if not parts:\n",
    "        out[\"geometry\"] = out.geometry.buffer(buffer_m)\n",
    "\n",
    "    out = gpd.GeoDataFrame(out, geometry=\"geometry\", crs=iso_gdf.crs).reset_index(drop=True)\n",
    "    out[\"iso_pid\"] = np.arange(len(out))  # уникальный ID полигона изолинии (полосы)\n",
    "    return out[[\"iso_pid\", \"geometry\"]]\n",
    "\n",
    "def rings_to_fill_polys(iso_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    «Половина изолинии с более высоким уровнем»: берём ВНУТРЕННОСТЬ замкнутых линий.\n",
    "    - Для Polygon/MultiPolygon оставляем как есть (их внутренность уже задана).\n",
    "    - Для LineString/MultiLineString создаём Polygon из замкнутых колец (is_ring=True).\n",
    "    Возвращает GeoDataFrame с fill_id и geometry (могут пересекаться/вкладываться).\n",
    "    \"\"\"\n",
    "    geoms = []\n",
    "    for geom in iso_gdf.geometry:\n",
    "        if geom is None or geom.is_empty:\n",
    "            continue\n",
    "        gtype = geom.geom_type\n",
    "        if gtype in (\"Polygon\", \"MultiPolygon\"):\n",
    "            if gtype == \"Polygon\":\n",
    "                geoms.append(Polygon(geom.exterior))\n",
    "            else:\n",
    "                for p in geom.geoms:\n",
    "                    geoms.append(Polygon(p.exterior))\n",
    "        elif gtype in (\"LineString\", \"MultiLineString\"):\n",
    "            if gtype == \"LineString\":\n",
    "                if getattr(geom, \"is_ring\", False):\n",
    "                    geoms.append(Polygon(geom.coords))\n",
    "            else:\n",
    "                for ls in geom.geoms:\n",
    "                    if getattr(ls, \"is_ring\", False):\n",
    "                        geoms.append(Polygon(ls.coords))\n",
    "        # прочие типы игнорируем\n",
    "    if not geoms:\n",
    "        return gpd.GeoDataFrame({\"fill_id\": [], \"geometry\": []}, geometry=\"geometry\", crs=iso_gdf.crs)\n",
    "\n",
    "    # фиксим валидность тонким buffer(0)\n",
    "    geoms = [g.buffer(0) if isinstance(g, (Polygon, MultiPolygon)) else g for g in geoms]\n",
    "    fill = gpd.GeoDataFrame({\"geometry\": geoms}, geometry=\"geometry\", crs=iso_gdf.crs)\n",
    "    fill = fill[~fill.geometry.is_empty & fill.geometry.notna()].copy().reset_index(drop=True)\n",
    "    fill[\"fill_id\"] = np.arange(len(fill))\n",
    "    return fill[[\"fill_id\", \"geometry\"]]\n",
    "\n",
    "def sjoin_intersects(left: gpd.GeoDataFrame, right: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    try:\n",
    "        return gpd.sjoin(left, right, predicate=\"intersects\", how=\"left\")\n",
    "    except TypeError:\n",
    "        return gpd.sjoin(left, right, op=\"intersects\", how=\"left\")\n",
    "\n",
    "def sjoin_within(left: gpd.GeoDataFrame, right: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    try:\n",
    "        return gpd.sjoin(left, right, predicate=\"within\", how=\"left\")\n",
    "    except TypeError:\n",
    "        return gpd.sjoin(left, right, op=\"within\", how=\"left\")\n",
    "\n",
    "# --- ЗАГРУЗКА ---\n",
    "isoln = gpd.read_file(PATH_ISOLINE)\n",
    "grid  = gpd.read_file(PATH_GRID)\n",
    "\n",
    "# CRS → метрический\n",
    "# grid  = to_metric_crs(grid)\n",
    "isoln = isoln.to_crs(grid.crs)\n",
    "\n",
    "# --- ИЗОЛИНИИ → ПОЛОСЫ (buffer) И УРОВНИ ВЛОЖЕННОСТИ ДЛЯ ПОЛОС ---\n",
    "iso_polys = isolines_to_polys(isoln, buffer_m=ISO_BUFFER_M).copy()\n",
    "iso_polys[\"iso_pid\"] = pd.to_numeric(iso_polys[\"iso_pid\"], errors=\"coerce\").astype(\"Int64\")\n",
    "iso_polys = gpd.GeoDataFrame(iso_polys, geometry=\"geometry\", crs=isoln.crs)\n",
    "\n",
    "# representative_point каждого полигона-полосы → считаем, в скольких полосах он within; минус 1 (сам себя)\n",
    "iso_pts = iso_polys[[\"iso_pid\", \"geometry\"]].copy()\n",
    "iso_pts[\"geometry\"] = iso_pts.geometry.representative_point()\n",
    "within_pairs = gpd.sjoin(\n",
    "    iso_pts, iso_polys[[\"iso_pid\", \"geometry\"]],\n",
    "    how=\"left\", predicate=\"within\", lsuffix=\"pt\", rsuffix=\"poly\"\n",
    ")\n",
    "lvl = within_pairs.groupby(\"iso_pid_pt\", dropna=False).size() - 1\n",
    "iso_levels = (\n",
    "    lvl.reset_index()\n",
    "       .rename(columns={\"iso_pid_pt\": \"iso_pid\", 0: \"iso_level\"})\n",
    "       .astype({\"iso_pid\": \"Int64\"})\n",
    ")\n",
    "iso_polys = iso_polys.merge(iso_levels, on=\"iso_pid\", how=\"left\")\n",
    "iso_polys[\"iso_level\"] = iso_polys[\"iso_level\"].fillna(0).astype(int)\n",
    "\n",
    "# --- НОВОЕ: ВНУТРЕННИЕ ПОЛИГОНЫ КОЛЕЦ (половина изолинии с более высоким уровнем) ---\n",
    "iso_fill = rings_to_fill_polys(isoln)  # «внутренняя сторона» замкнутых линий\n",
    "\n",
    "# Уровень вложенности для внутренних полигонов (по тому же принципу)\n",
    "if len(iso_fill) > 0:\n",
    "    fill_pts = iso_fill[[\"fill_id\", \"geometry\"]].copy()\n",
    "    fill_pts[\"geometry\"] = fill_pts.geometry.representative_point()\n",
    "    fill_pairs = gpd.sjoin(\n",
    "        fill_pts, iso_fill[[\"fill_id\", \"geometry\"]],\n",
    "        how=\"left\", predicate=\"within\", lsuffix=\"pt\", rsuffix=\"poly\"\n",
    "    )\n",
    "    flvl = fill_pairs.groupby(\"fill_id_pt\", dropna=False).size() - 1\n",
    "    fill_levels = (\n",
    "        flvl.reset_index()\n",
    "            .rename(columns={\"fill_id_pt\": \"fill_id\", 0: \"fill_level\"})\n",
    "            .astype({\"fill_id\": \"Int64\"})\n",
    "    )\n",
    "    iso_fill = iso_fill.merge(fill_levels, on=\"fill_id\", how=\"left\")\n",
    "    iso_fill[\"fill_level\"] = iso_fill[\"fill_level\"].fillna(0).astype(int)\n",
    "\n",
    "# --- ТЕГГИНГ КЛЕТОК ---\n",
    "# 1) Пересечения с полосами (как было)\n",
    "cells = grid[[\"geometry\"]].reset_index(drop=False).rename(columns={\"index\": \"cell_id\"})\n",
    "hit = gpd.sjoin(\n",
    "    cells, iso_polys[[\"iso_pid\", \"iso_level\", \"geometry\"]],\n",
    "    how=\"left\", predicate=\"intersects\"\n",
    ")\n",
    "hit_nonnull = hit[hit[\"iso_pid\"].notna()].copy()\n",
    "agg_inter = (\n",
    "    hit_nonnull.groupby(\"cell_id\", dropna=False)\n",
    "      .agg(\n",
    "          iso_pids=(\"iso_pid\", lambda s: sorted(set(int(x) for x in pd.to_numeric(s, errors=\"coerce\").dropna().tolist()))),\n",
    "          iso_level_raw=(\"iso_level\", \"max\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "grid = grid.reset_index(drop=False).rename(columns={\"index\": \"cell_id\"})\n",
    "grid = grid.merge(agg_inter, on=\"cell_id\", how=\"left\")\n",
    "grid[\"iso_pids\"] = grid[\"iso_pids\"].apply(lambda v: v if isinstance(v, list) else [])\n",
    "grid[\"inside_iso_raw\"] = grid[\"iso_pids\"].apply(lambda v: len(v) > 0)\n",
    "grid[\"iso_level_raw\"] = pd.to_numeric(grid[\"iso_level_raw\"], errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "# 2) ДОПОЛНИТЕЛЬНО: попадание центроидов внутрь «внутренних» полигонов колец\n",
    "if len(iso_fill) > 0:\n",
    "    cells_pts = cells.copy()\n",
    "    # representative_point устойчивее centroid для невалидной геометрии\n",
    "    cells_pts[\"geometry\"] = grid.geometry.representative_point().values\n",
    "    hit_fill = gpd.sjoin(\n",
    "        cells_pts, iso_fill[[\"fill_id\", \"fill_level\", \"geometry\"]],\n",
    "        how=\"left\", predicate=\"within\"\n",
    "    )\n",
    "    hit_fill_nonnull = hit_fill[hit_fill[\"fill_id\"].notna()].copy()\n",
    "    agg_fill = (\n",
    "        hit_fill_nonnull.groupby(\"cell_id\", dropna=False)\n",
    "            .agg(fill_level=(\"fill_level\", \"max\"))\n",
    "            .reset_index()\n",
    "    )\n",
    "    grid = grid.merge(agg_fill, on=\"cell_id\", how=\"left\")\n",
    "    # клетки внутри внутренних полигонов тоже считаются raw-True\n",
    "    inside_by_fill = grid[\"fill_level\"].notna()\n",
    "    grid.loc[inside_by_fill, \"inside_iso_raw\"] = True\n",
    "    # уровень берём максимумом из прежнего и «внутреннего»\n",
    "    grid[\"iso_level_raw\"] = np.fmax(\n",
    "        grid[\"iso_level_raw\"].astype(float).fillna(-1),\n",
    "        pd.to_numeric(grid[\"fill_level\"], errors=\"coerce\").fillna(-1)\n",
    "    )\n",
    "    grid[\"iso_level_raw\"].replace(-1, np.nan, inplace=True)\n",
    "else:\n",
    "    grid[\"fill_level\"] = np.nan\n",
    "\n",
    "# --- ПРАВИЛО «3 СТОРОНЫ» ДЛЯ ПУСТЫХ КЛЕТОК (соседство по общему РЕБРУ) ---\n",
    "pairs = gpd.sjoin(\n",
    "    grid[[\"cell_id\", \"geometry\"]], grid[[\"cell_id\", \"geometry\"]],\n",
    "    how=\"left\", predicate=\"touches\", lsuffix=\"a\", rsuffix=\"b\"\n",
    ")\n",
    "pairs = pairs[(pairs[\"cell_id_a\"] != pairs[\"cell_id_b\"]) & pairs[\"cell_id_b\"].notna()].copy()\n",
    "pairs[\"cell_id_b\"] = pairs[\"cell_id_b\"].astype(int)\n",
    "\n",
    "# порог \"существенного\" ребра: >= 20% от характерной длины ребра клетки (~sqrt(area))\n",
    "geom_list = list(grid.geometry.values)\n",
    "pos = {rid: i for i, rid in enumerate(grid[\"cell_id\"].values)}\n",
    "edge_len_est = np.sqrt(np.maximum(grid.geometry.area.values, 1e-9))\n",
    "thr_len = EDGE_SHARE_FRAC * edge_len_est\n",
    "\n",
    "def _is_edge_neighbor(a: int, b: int) -> bool:\n",
    "    ia, ib = pos[a], pos[b]\n",
    "    inter = geom_list[ia].boundary.intersection(geom_list[ib].boundary)\n",
    "    length = getattr(inter, \"length\", 0.0)\n",
    "    return length >= min(thr_len[ia], thr_len[ib])\n",
    "\n",
    "pairs[\"edge_ok\"] = pairs.apply(lambda r: _is_edge_neighbor(int(r[\"cell_id_a\"]), int(r[\"cell_id_b\"])), axis=1)\n",
    "pairs = pairs[pairs[\"edge_ok\"]]\n",
    "\n",
    "neighbors = {rid: [] for rid in grid[\"cell_id\"].values}\n",
    "for ra, rb in pairs[[\"cell_id_a\", \"cell_id_b\"]].itertuples(index=False):\n",
    "    neighbors[int(ra)].append(int(rb))\n",
    "\n",
    "inside_map = dict(zip(grid[\"cell_id\"].values, grid[\"inside_iso_raw\"].values))\n",
    "promote = []\n",
    "for rid, neighs in neighbors.items():\n",
    "    if not inside_map[rid]:\n",
    "        if sum(1 for nb in neighs if inside_map.get(nb, False)) >= 3:\n",
    "            promote.append(rid)\n",
    "\n",
    "grid[\"inside_iso_closed\"] = grid.apply(\n",
    "    lambda r: bool(r[\"inside_iso_raw\"] or (r[\"cell_id\"] in promote)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- УРОВЕНЬ ДЛЯ ДОЗАЖЖЁННЫХ КЛЕТОК — мода уровней соседей raw-True ---\n",
    "level_map = dict(zip(grid[\"cell_id\"].values, grid[\"iso_level_raw\"].values))\n",
    "\n",
    "def _neighbor_level_mode(rid: int) -> float:\n",
    "    vals = [level_map.get(nb) for nb in neighbors.get(rid, []) if inside_map.get(nb, False) and pd.notna(level_map.get(nb))]\n",
    "    if not vals:\n",
    "        return np.nan\n",
    "    return int(pd.Series(vals).value_counts().index[0])\n",
    "\n",
    "grid[\"iso_level\"] = grid[\"iso_level_raw\"]\n",
    "need_fill = grid[\"inside_iso_closed\"] & (~grid[\"inside_iso_raw\"])\n",
    "grid.loc[need_fill, \"iso_level\"] = grid.loc[need_fill, \"cell_id\"].apply(_neighbor_level_mode)\n",
    "\n",
    "# --- ВЫВОД ---\n",
    "cols_out = [\"cell_id\", \"geometry\", \"iso_pids\", \"inside_iso_raw\", \"inside_iso_closed\", \"iso_level_raw\", \"iso_level\", \"fill_level\"]\n",
    "grid_out = gpd.GeoDataFrame(grid[cols_out].copy(), geometry=\"geometry\", crs=grid.crs)\n",
    "\n",
    "OUT_TAGGED = PATH_GRID.with_name(f\"{PATH_GRID.stem}_tagged_rings.geojson\")\n",
    "grid_out.to_file(OUT_TAGGED, driver=\"GeoJSON\")\n",
    "print(\n",
    "    \"OK →\", OUT_TAGGED, \"\\n\",\n",
    "    f\"Всего клеток: {len(grid_out)}, raw True: {int(grid_out.inside_iso_raw.sum())}, closed True: {int(grid_out.inside_iso_closed.sum())}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK → buildings_clustered_cells_with_building.geojson  (клеток: 10065, жилых: 1463, diag-only: 69)\n",
      "OK → buildings_clustered_buildings_rects.geojson  (элементов: 1430, сервис-корпусов: 7)\n",
      "OK → buildings_clustered_buildings_merged.geojson (полигонов: 253, schools: 1, kindergartens: 5, polyclinics: 1, living_house: 246)\n",
      "Uniformity CSV: buildings_clustered_service_uniformity.csv (по УЧАСТКАМ)\n",
      "Service sites: buildings_clustered_service_sites.geojson (участков: 7)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Алгоритм размещения сервисов с участками:\n",
    "# - Участки только прямоугольные, как набор клеток.\n",
    "# - Корпус сервиса вписывается внутрь core-окна участка (внутренний буфер ≥1 клетка).\n",
    "# - Зазоры: до домов ≥1 клетка (Chebyshev ≥2); между любыми участками ≥1 клетка (Chebyshev ≥2).\n",
    "# - НОВОЕ: между участками ОДНОГО ТИПА ≥10 клеток (Chebyshev ≥10).\n",
    "# - Размещение выполняется раунд-робином по типам сервисов: за один цикл ставим по одному объекту каждого типа.\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# ---------- ПУТИ ----------\n",
    "BASE_GRID = Path(\"/root/globalmapper_learning/out_2/buildings_clustered.geojson\")\n",
    "INPUT_CELLS_PATH = BASE_GRID.with_name(f\"{BASE_GRID.stem}_tagged_rings.geojson\")\n",
    "PATH_ZONES = Path(\"/root/globalmapper_learning/zones.geojson\")\n",
    "\n",
    "# Если работаете в этой среде, можно подхватить из /mnt/data\n",
    "if Path(\"/mnt/data/buildings_clustered_tagged_rings.geojson\").exists():\n",
    "    INPUT_CELLS_PATH = Path(\"/mnt/data/buildings_clustered_tagged_rings.geojson\")\n",
    "if Path(\"/mnt/data/zones.geojson\").exists():\n",
    "    PATH_ZONES = Path(\"/mnt/data/zones.geojson\")\n",
    "\n",
    "OUT_CELLS       = INPUT_CELLS_PATH.with_name(f\"{INPUT_CELLS_PATH.stem.replace('_tagged_rings','')}_cells_with_building.geojson\")\n",
    "OUT_RECTS       = INPUT_CELLS_PATH.with_name(f\"{INPUT_CELLS_PATH.stem.replace('_tagged_rings','')}_buildings_rects.geojson\")\n",
    "OUT_MERGED      = INPUT_CELLS_PATH.with_name(f\"{INPUT_CELLS_PATH.stem.replace('_tagged_rings','')}_buildings_merged.geojson\")\n",
    "OUT_SVC_METRICS = INPUT_CELLS_PATH.with_name(f\"{INPUT_CELLS_PATH.stem.replace('_tagged_rings','')}_service_uniformity.csv\")\n",
    "OUT_SVC_SITES   = INPUT_CELLS_PATH.with_name(f\"{INPUT_CELLS_PATH.stem.replace('_tagged_rings','')}_service_sites.geojson\")\n",
    "\n",
    "# ---------- ПАРАМЕТРЫ ----------\n",
    "MAX_RUN                = 8\n",
    "NEIGH_EMPTY_THR        = 3\n",
    "CELL_SIZE_M            = 15.0\n",
    "EDGE_SHARE_FRAC        = 0.2\n",
    "MERGE_PREDICATE        = \"intersects\"\n",
    "MERGE_FIX_EPS          = 0.0\n",
    "\n",
    "# Лимиты сервисов на квартал\n",
    "MAX_SERVICES_PER_ZONE = {\"school\": 3, \"kindergarten\": 5, \"polyclinics\": 1}\n",
    "\n",
    "# Рандомизация форм\n",
    "RANDOMIZE_SERVICE_FORMS = True\n",
    "SERVICE_RANDOM_SEED     = 42\n",
    "\n",
    "# Зазоры\n",
    "GAP_TO_HOUSES_CHEB      = 2  # территории держат ≥1 клетку до домов\n",
    "GAP_BETWEEN_SITES_CHEB  = 2  # общая дистанция между участками (любыми типами)\n",
    "SAME_TYPE_SITE_GAP_CHEB = 10 # НОВОЕ: между участками одного типа ≥10 клеток\n",
    "INNER_MARGIN_CELLS      = 1  # корпус внутри территории с полем безопасности 1 клетка\n",
    "\n",
    "# Нормативные площади участков (из таблицы сопоставлений)\n",
    "SERVICE_SITE_RULES = {\n",
    "    (\"school\", \"RECT_5x2_WITH_OPEN_3\"):      {\"capacity\": 600,  \"site_area_m2\": 33000.0},\n",
    "    (\"school\", \"H_5x4\"):                      {\"capacity\": 800,  \"site_area_m2\": 36000.0},\n",
    "    (\"school\", \"RING_5x5_WITH_COURTYARD\"):    {\"capacity\": 1100, \"site_area_m2\": 39600.0},\n",
    "    (\"kindergarten\", \"LINE3\"):                {\"capacity\": 60,   \"site_area_m2\": 2640.0},\n",
    "    (\"kindergarten\", \"W5\"):                   {\"capacity\": 100,  \"site_area_m2\": 4400.0},\n",
    "    (\"kindergarten\", \"H7\"):                   {\"capacity\": 150,  \"site_area_m2\": 5700.0},\n",
    "    (\"polyclinics\", \"RECT_2x4\"):              {\"capacity\": 300,  \"site_area_m2\": 3000.0},\n",
    "}\n",
    "\n",
    "# ---------------- УТИЛИТЫ ГЕО/ИНДЕКСАЦИЯ ----------------\n",
    "def _min_site_cells_for_service_with_margin(svc: str,\n",
    "                                            shape_variants: dict[str, list[tuple[str, list[list[tuple[int,int]]]]]],\n",
    "                                            inner_margin_cells: int = 1) -> int:\n",
    "    # минимальные клетки участка, чтобы любой вариант корпуса svc влез в core с отступом\n",
    "    need = 0\n",
    "    if svc not in shape_variants: \n",
    "        return 0\n",
    "    best = None\n",
    "    for _pat, vars_ in shape_variants[svc]:\n",
    "        for var in vars_:\n",
    "            vr = [dr for dr,_ in var]; vc = [dc for _,dc in var]\n",
    "            h = (max(vr) - min(vr) + 1) + 2*inner_margin_cells\n",
    "            w = (max(vc) - min(vc) + 1) + 2*inner_margin_cells\n",
    "            cells_needed = h * w\n",
    "            best = cells_needed if best is None else min(best, cells_needed)\n",
    "    return 0 if best is None else best\n",
    "\n",
    "def _sjoin_touches(a: gpd.GeoDataFrame, b: gpd.GeoDataFrame):\n",
    "    try:\n",
    "        return gpd.sjoin(a, b, how=\"left\", predicate=\"touches\", lsuffix=\"a\", rsuffix=\"b\")\n",
    "    except TypeError:\n",
    "        return gpd.sjoin(a, b, how=\"left\", op=\"touches\", lsuffix=\"a\", rsuffix=\"b\")\n",
    "\n",
    "def _sjoin_generic(a: gpd.GeoDataFrame, b: gpd.GeoDataFrame, predicate: str):\n",
    "    try:\n",
    "        return gpd.sjoin(a, b, how=\"left\", predicate=predicate, lsuffix=\"l\", rsuffix=\"r\")\n",
    "    except TypeError:\n",
    "        return gpd.sjoin(a, b, how=\"left\", op=predicate, lsuffix=\"l\", rsuffix=\"r\")\n",
    "\n",
    "def _grid_indices(gdf: gpd.GeoDataFrame):\n",
    "    c = gdf.geometry.centroid\n",
    "    x = c.x.values; y = c.y.values\n",
    "    cell_step = np.median(np.sqrt(np.maximum(gdf.geometry.area.values, 1e-9)))\n",
    "    x0, y0 = float(np.min(x)), float(np.min(y))\n",
    "    col = np.rint((x - x0) / cell_step).astype(int)\n",
    "    row = np.rint((y - y0) / cell_step).astype(int)\n",
    "    return row, col, x0, y0, float(cell_step)\n",
    "\n",
    "def _enforce_line_blocks(df, line_key, order_key, mask_key, max_run: int):\n",
    "    out = df[mask_key].copy()\n",
    "    for _, sub in df.loc[df[mask_key]].groupby(line_key):\n",
    "        sub = sub.sort_values(order_key)\n",
    "        idx = sub.index.to_numpy(); ordv = sub[order_key].to_numpy()\n",
    "        breaks = np.where(np.diff(ordv) != 1)[0] + 1\n",
    "        segments = np.split(np.arange(len(ordv)), breaks)\n",
    "        for seg in segments:\n",
    "            if len(seg) <= max_run: continue\n",
    "            run = 0; place_gap = False\n",
    "            for k in seg:\n",
    "                i = idx[k]\n",
    "                if place_gap:\n",
    "                    out.loc[i] = False; place_gap = False; run = 0\n",
    "                else:\n",
    "                    if run < max_run:\n",
    "                        out.loc[i] = True; run += 1\n",
    "                        if run == max_run: place_gap = True\n",
    "                    else:\n",
    "                        out.loc[i] = False; run = 0\n",
    "    return out\n",
    "\n",
    "def _components(nodes: list[int], adj: dict[int, list[int]]) -> list[list[int]]:\n",
    "    node_set = set(nodes); seen, comps = set(), []\n",
    "    for v in nodes:\n",
    "        if v in seen: continue\n",
    "        stack, comp = [v], [v]; seen.add(v)\n",
    "        while stack:\n",
    "            u = stack.pop()\n",
    "            for w in adj[u]:\n",
    "                if w in node_set and w not in seen:\n",
    "                    seen.add(w); stack.append(w); comp.append(w)\n",
    "        comps.append(comp)\n",
    "    return comps\n",
    "\n",
    "def _pca_order(pts: np.ndarray) -> np.ndarray:\n",
    "    if len(pts) <= 2: return np.argsort(pts[:,0] + pts[:,1])\n",
    "    P = pts - pts.mean(axis=0, keepdims=True)\n",
    "    _, _, Vt = np.linalg.svd(P, full_matrices=False); axis = Vt[0]\n",
    "    t = P @ axis; return np.argsort(t)\n",
    "\n",
    "def _make_valid(g):\n",
    "    try: return g.buffer(0)\n",
    "    except Exception: return g\n",
    "\n",
    "def _compute_neighbors(cells: gpd.GeoDataFrame, edge_share_frac: float = 0.2):\n",
    "    \"\"\"\n",
    "    Надёжная версия: вычисляет «смежность по стороне» на лету (без 'edge_ok').\n",
    "    \"\"\"\n",
    "    left = cells[[\"geometry\"]].reset_index().rename(columns={\"index\": \"ida\"})\n",
    "    right = cells[[\"geometry\"]].reset_index().rename(columns={\"index\": \"idb\"})\n",
    "    pairs = _sjoin_touches(left, right)\n",
    "    if \"idb\" not in pairs.columns and \"index_right\" in pairs.columns:\n",
    "        pairs = pairs.rename(columns={\"index_right\": \"idb\"})\n",
    "    pairs = pairs[(pairs[\"ida\"] != pairs[\"idb\"]) & pairs[\"idb\"].notna()].copy()\n",
    "\n",
    "    neighbors_all = {i: [] for i in range(len(cells))}\n",
    "    neighbors_side = {i: [] for i in range(len(cells))}\n",
    "    neighbors_diag = {i: [] for i in range(len(cells))}\n",
    "    if len(pairs) > 0:\n",
    "        pairs[\"idb\"] = pairs[\"idb\"].astype(int)\n",
    "        geom_list = list(cells.geometry.values)\n",
    "        edge_len_est = np.sqrt(np.maximum(cells.geometry.area.values, 1e-9))\n",
    "        thr_len = edge_share_frac * edge_len_est\n",
    "\n",
    "        def _is_edge_neighbor(a: int, b: int) -> bool:\n",
    "            try:\n",
    "                inter = geom_list[a].boundary.intersection(geom_list[b].boundary)\n",
    "                length = getattr(inter, \"length\", 0.0)\n",
    "            except Exception:\n",
    "                length = 0.0\n",
    "            return length >= min(thr_len[a], thr_len[b])\n",
    "\n",
    "        for a, b in pairs[[\"ida\", \"idb\"]].itertuples(index=False):\n",
    "            a = int(a); b = int(b)\n",
    "            eok = _is_edge_neighbor(a, b)\n",
    "            neighbors_all[a].append(b)\n",
    "            (neighbors_side if eok else neighbors_diag)[a].append(b)\n",
    "\n",
    "        # симметрия\n",
    "        for i in range(len(cells)):\n",
    "            for dct in (neighbors_all, neighbors_side, neighbors_diag):\n",
    "                for j in list(dct[i]):\n",
    "                    if i not in dct[j]:\n",
    "                        dct[j].append(i)\n",
    "\n",
    "    inside = cells[\"inside_iso_closed\"].fillna(False).to_numpy().astype(bool)\n",
    "    empty_neighs = np.zeros(len(cells), dtype=int)\n",
    "    missing = np.zeros(len(cells), dtype=int)\n",
    "    for i in range(len(cells)):\n",
    "        nn = list(set(neighbors_all.get(i, [])))\n",
    "        empty_neighs[i] = sum(1 for j in nn if not inside[j])\n",
    "        missing[i] = max(0, 8 - len(nn))\n",
    "\n",
    "    return neighbors_all, neighbors_side, neighbors_diag, empty_neighs, missing\n",
    "\n",
    "# ---------------- ПАТТЕРНЫ КОРПУСОВ СЕРВИСОВ ----------------\n",
    "def _pattern_library():\n",
    "    lib = {}\n",
    "    # Kindergarten\n",
    "    k_h7 = [(-1,-1),(0,-1),(1,-1),(0,0),(-1,1),(0,1),(1,1)]\n",
    "    k_w5 = [(0,0),(1,1),(0,2),(1,3),(0,4)]\n",
    "    line3 = [(0,0),(0,1),(0,2)]\n",
    "    lib[\"kindergarten\"] = [\n",
    "        (\"H7\", k_h7, True),\n",
    "        (\"W5\", k_w5, True),\n",
    "        (\"LINE3\", line3, True),\n",
    "    ]\n",
    "\n",
    "    # Polyclinics\n",
    "    rect_2x4 = [(r, c) for r in range(2) for c in range(4)]\n",
    "    lib[\"polyclinics\"] = [\n",
    "        (\"RECT_2x4\", rect_2x4, True)\n",
    "    ]\n",
    "\n",
    "    # School\n",
    "    s_h_5x4 = [(r,0) for r in range(5)] + [(r,3) for r in range(5)] + [(2,c) for c in range(4)]\n",
    "    ring = []\n",
    "    for r in range(5):\n",
    "        for c in range(5):\n",
    "            if (r in {0,4} or c in {0,4}) and not (r in {0,4} and c in {0,4}):\n",
    "                ring.append((r,c))\n",
    "    s_5x2_open = [(1,c) for c in range(5)] + [(0,0),(0,4)]\n",
    "    lib[\"school\"] = [\n",
    "        (\"H_5x4\", s_h_5x4, True),\n",
    "        (\"RING_5x5_WITH_COURTYARD\", ring, False),\n",
    "        (\"RECT_5x2_WITH_OPEN_3\", s_5x2_open, True),\n",
    "    ]\n",
    "    return lib\n",
    "\n",
    "def _transform_offsets(offsets, rot_k: int, mirror: bool):\n",
    "    out = []\n",
    "    for (dr, dc) in offsets:\n",
    "        r, c = dr, dc\n",
    "        for _ in range(rot_k % 4): r, c = c, -r\n",
    "        if mirror: c = -c\n",
    "        out.append((r, c))\n",
    "    minr = min(r for r,_ in out); minc = min(c for _,c in out)\n",
    "    return [(r - minr, c - minc) for (r,c) in out]\n",
    "\n",
    "def _shape_variants(offsets, allow_rotations: bool):\n",
    "    variants = set()\n",
    "    rots = [0,1,2,3] if allow_rotations else [0]\n",
    "    mirrors = [False, True] if allow_rotations else [False]\n",
    "    for k in rots:\n",
    "        for m in mirrors:\n",
    "            var = tuple(sorted(_transform_offsets(offsets, k, m)))\n",
    "            variants.add(var)\n",
    "    return [list(v) for v in variants]\n",
    "\n",
    "def _shape_length(var: list[tuple[int,int]]) -> int:\n",
    "    rs = [dr for dr,_ in var]; cs = [dc for _,dc in var]\n",
    "    return max(max(rs)-min(rs)+1, max(cs)-min(cs)+1)\n",
    "\n",
    "# ---------------- ТЕРРИТОРИИ: ТОЛЬКО ПРЯМОУГОЛЬНИКИ ----------------\n",
    "def _site_cells_required(area_m2: float, cell_size_m: float) -> int:\n",
    "    return int(math.ceil(max(area_m2, 1.0) / (cell_size_m * cell_size_m)))\n",
    "\n",
    "def _rect_variants_for_cells(ncells: int, max_variants: int = 12, ar_min: float = 0.33, ar_max: float = 3.0):\n",
    "    base = int(round(math.sqrt(ncells)))\n",
    "    pairs = []\n",
    "    span = max(1, base) + 12\n",
    "    for r in range(1, span+1):\n",
    "        c = int(math.ceil(ncells / r))\n",
    "        ar = max(r, c) / max(1.0, min(r, c))\n",
    "        if ar_min <= ar <= ar_max:\n",
    "            pairs.append((r, c, r*c - ncells))\n",
    "    pairs = sorted(pairs, key=lambda t: (t[2], abs(t[0]-t[1])))\n",
    "    pairs = pairs[:max_variants]\n",
    "    variants = []\n",
    "    for r, c, _ in pairs:\n",
    "        offs = [(dr, dc) for dr in range(r) for dc in range(c)]\n",
    "        variants.append((f\"RECT_{r}x{c}\", offs))\n",
    "    return variants\n",
    "\n",
    "def _territory_shape_variants(area_m2: float, cell_size_m: float) -> list[tuple[str, list[tuple[int,int]]]]:\n",
    "    ncells = _site_cells_required(area_m2, cell_size_m)\n",
    "    return _rect_variants_for_cells(ncells, max_variants=12)\n",
    "\n",
    "# ---------------- ПРОЧЕЕ ----------------\n",
    "def _centroid_of_indices(cells: gpd.GeoDataFrame, idxs: list[int]) -> Point:\n",
    "    return unary_union([cells.geometry[i] for i in idxs]).representative_point()\n",
    "\n",
    "def _min_cheb_between_sets(cells: gpd.GeoDataFrame, A: list[int], B: list[int]) -> int:\n",
    "    if not A or not B: return 10**9\n",
    "    ar = cells.loc[A, \"row_i\"].to_numpy(); ac = cells.loc[A, \"col_j\"].to_numpy()\n",
    "    br = cells.loc[B, \"row_i\"].to_numpy(); bc = cells.loc[B, \"col_j\"].to_numpy()\n",
    "    best = 10**9\n",
    "    for i in range(len(ar)):\n",
    "        dr = np.abs(br - ar[i]); dc = np.abs(bc - ac[i])\n",
    "        d = int(np.min(np.maximum(dr, dc)))\n",
    "        if d < best: best = d\n",
    "        if best == 0: break\n",
    "    return best\n",
    "\n",
    "def _positions_from_center_or_edges(svc: str, rmin: int, rmax: int, cmin: int, cmax: int,\n",
    "                                    r_center: float, c_center: float, invert: bool = False) -> list[tuple[int,int]]:\n",
    "    pos = [(r0, c0) for r0 in range(rmin, rmax+1) for c0 in range(cmin, cmax+1)]\n",
    "    def d2(rc): return (rc[0]-r_center)**2 + (rc[1]-c_center)**2\n",
    "    pos.sort(key=d2, reverse=invert and (svc == \"kindergarten\"))\n",
    "    return pos\n",
    "\n",
    "# ---------- НОРМАТИВЫ → Параметры площадок ----------\n",
    "def _service_site_spec(svc: str, pattern_name: str) -> tuple[float, int]:\n",
    "    spec = SERVICE_SITE_RULES.get((svc, pattern_name))\n",
    "    if spec:\n",
    "        return float(spec[\"site_area_m2\"]), int(spec[\"capacity\"])\n",
    "    if svc == \"school\":       return 33000.0, 600\n",
    "    if svc == \"kindergarten\": return 4400.0, 100\n",
    "    if svc == \"polyclinics\":  return 3000.0, 300\n",
    "    return 2000.0, 0\n",
    "\n",
    "# ------------------------------- ЗАГРУЗКА/ПОДГОТОВКА -------------------------------\n",
    "cells = gpd.read_file(INPUT_CELLS_PATH).reset_index(drop=True)\n",
    "if \"inside_iso_closed\" not in cells.columns:\n",
    "    raise ValueError(\"Во входном слое отсутствует колонка 'inside_iso_closed'.\")\n",
    "cells[\"inside_iso_closed\"] = cells[\"inside_iso_closed\"].fillna(False).astype(bool)\n",
    "cells[\"iso_level\"] = pd.to_numeric(cells.get(\"iso_level\"), errors=\"coerce\")\n",
    "cells[\"service\"] = None  # корпуса сервисов будут помечаться позже\n",
    "\n",
    "row_i, col_j, x0, y0, step_est = _grid_indices(cells)\n",
    "cells[\"row_i\"] = row_i; cells[\"col_j\"] = col_j\n",
    "\n",
    "zones = gpd.read_file(PATH_ZONES).to_crs(cells.crs).reset_index(drop=True)\n",
    "zone_id_col = \"zone_id\"\n",
    "if \"id\" in zones.columns: zones[zone_id_col] = zones[\"id\"]\n",
    "else: zones[zone_id_col] = np.arange(len(zones))\n",
    "zone_name_col = \"zone\"\n",
    "if zone_name_col not in zones.columns:\n",
    "    for alt in [\"functional_zone_type_name\", \"zone_type\", \"zone_name\"]:\n",
    "        if alt in zones.columns:\n",
    "            zones[zone_name_col] = zones[alt]; break\n",
    "if zone_name_col not in zones.columns: zones[zone_name_col] = \"unknown\"\n",
    "\n",
    "cells_zone = gpd.sjoin(\n",
    "    cells[[\"geometry\"]].reset_index().rename(columns={\"index\":\"cell_idx\"}),\n",
    "    zones[[zone_id_col, zone_name_col, \"geometry\"]],\n",
    "    how=\"left\", predicate=\"within\"\n",
    ").drop_duplicates(\"cell_idx\")\n",
    "\n",
    "cells = cells.merge(\n",
    "    cells_zone[[\"cell_idx\", zone_id_col, zone_name_col]],\n",
    "    left_index=True, right_on=\"cell_idx\", how=\"left\"\n",
    ").drop(columns=[\"cell_idx\"])\n",
    "\n",
    "cells[zone_name_col] = cells[zone_name_col].astype(str).str.lower().str.strip()\n",
    "cells[\"is_residential_zone\"] = cells[zone_name_col].eq(\"residential\")\n",
    "\n",
    "# Соседства/внешность\n",
    "neighbors_all, neighbors_side, neighbors_diag, empty_neighs, missing = _compute_neighbors(\n",
    "    cells, edge_share_frac=EDGE_SHARE_FRAC\n",
    ")\n",
    "\n",
    "# ---------------- 1) ЖИЛЫЕ ДОМА (фиксируем) ----------------\n",
    "inside_mask = cells[\"inside_iso_closed\"].values\n",
    "is_external = np.zeros(len(cells), dtype=bool)\n",
    "for i in range(len(cells)):\n",
    "    if not inside_mask[i]: continue\n",
    "    is_external[i] = (empty_neighs[i] >= NEIGH_EMPTY_THR) or (missing[i] > 0)\n",
    "cells[\"candidate_building\"] = inside_mask & is_external\n",
    "\n",
    "cells[\"candidate_building\"] = _enforce_line_blocks(cells, \"row_i\", \"col_j\", \"candidate_building\", MAX_RUN)\n",
    "cells[\"is_building\"] = _enforce_line_blocks(cells, \"col_j\", \"row_i\", \"candidate_building\", MAX_RUN)\n",
    "\n",
    "# Промо внутренних соседей для «малых граничных»\n",
    "bbox = np.array([cells.geometry.bounds.minx.values,\n",
    "                 cells.geometry.bounds.miny.values,\n",
    "                 cells.geometry.bounds.maxx.values,\n",
    "                 cells.geometry.bounds.maxy.values]).T\n",
    "w = bbox[:, 2] - bbox[:, 0]; h = bbox[:, 3] - bbox[:, 1]\n",
    "is_small = (w < CELL_SIZE_M - 1e-6) | (h < CELL_SIZE_M - 1e-6)\n",
    "external_score = empty_neighs + missing\n",
    "\n",
    "is_b = cells[\"is_building\"].to_numpy().astype(bool)\n",
    "promote_targets = []\n",
    "for i in range(len(cells)):\n",
    "    if not (is_b[i] and is_external[i] and is_small[i]): continue\n",
    "    cand = [j for j in neighbors_side.get(i, []) if inside_mask[j]]\n",
    "    if not cand: cand = [j for j in neighbors_all.get(i, []) if inside_mask[j]]\n",
    "    cand = [j for j in cand if not is_b[j]]\n",
    "    if not cand: continue\n",
    "    j_best = min(cand, key=lambda j: (external_score[j], -empty_neighs[j]))\n",
    "    promote_targets.append(j_best)\n",
    "\n",
    "if promote_targets:\n",
    "    for j in promote_targets: is_b[j] = True\n",
    "    cells[\"is_building\"] = is_b\n",
    "    cells[\"is_building\"] = _enforce_line_blocks(cells, \"row_i\", \"col_j\", \"is_building\", MAX_RUN)\n",
    "    cells[\"is_building\"] = _enforce_line_blocks(cells, \"col_j\", \"row_i\", \"is_building\", MAX_RUN)\n",
    "\n",
    "# ---------------- 2) ГРУППИРОВКА ПО КВАРТАЛАМ + ПОДГОТОВКА К ТЕРРИТОРИЯМ ----------------\n",
    "idx_by_rc = {(int(r), int(c)): i for i,(r,c) in enumerate(zip(cells[\"row_i\"], cells[\"col_j\"]))}\n",
    "\n",
    "is_res = cells[\"is_residential_zone\"].fillna(False).values\n",
    "not_house = ~cells[\"is_building\"].fillna(False).values\n",
    "inside_true  = cells[\"inside_iso_closed\"].fillna(False).values\n",
    "inside_false = ~inside_true\n",
    "ok_iso = (cells[\"iso_level\"].fillna(0).values >= 0)\n",
    "\n",
    "zone_groups: dict[int, dict] = {}\n",
    "for zid, sub_all in cells[pd.notna(cells[\"zone_id\"])].groupby(cells[\"zone_id\"].astype(\"Int64\")):\n",
    "    zid = int(zid)\n",
    "    in_ids = sub_all.index[(is_res[sub_all.index]) & (inside_true[sub_all.index]) & ok_iso[sub_all.index] & not_house[sub_all.index]].to_list()\n",
    "    out_ids = sub_all.index[(is_res[sub_all.index]) & (inside_false[sub_all.index]) & not_house[sub_all.index]].to_list()\n",
    "    if not in_ids and not out_ids:\n",
    "        continue\n",
    "    sub_res = sub_all.index[is_res[sub_all.index]].to_list()\n",
    "    r_center = float(cells.loc[sub_res, \"row_i\"].median()) if len(sub_res) else float(sub_all[\"row_i\"].median())\n",
    "    c_center = float(cells.loc[sub_res, \"col_j\"].median()) if len(sub_res) else float(sub_all[\"col_j\"].median())\n",
    "    Lmax = int(pd.to_numeric(cells.loc[in_ids, \"iso_level\"], errors=\"coerce\").fillna(0).max()) if in_ids else 0\n",
    "    zone_groups[zid] = {\n",
    "        \"inside_ids\": in_ids,\n",
    "        \"outside_ids\": out_ids,\n",
    "        \"r_center\": r_center,\n",
    "        \"c_center\": c_center,\n",
    "        \"Lmax\": Lmax,\n",
    "    }\n",
    "\n",
    "svc_count_by_zone = {int(z): {\"school\":0,\"kindergarten\":0,\"polyclinics\":0} for z in zone_groups.keys()}\n",
    "rng = random.Random(SERVICE_RANDOM_SEED)\n",
    "\n",
    "lib = _pattern_library()\n",
    "shape_variants = {svc: [] for svc in lib.keys()}\n",
    "for svc, shapes in lib.items():\n",
    "    items = list(shapes)\n",
    "    if RANDOMIZE_SERVICE_FORMS: rng.shuffle(items)\n",
    "    for name, offsets, allow_rot in items:\n",
    "        vars_ = _shape_variants(offsets, allow_rot)\n",
    "        if RANDOMIZE_SERVICE_FORMS: rng.shuffle(vars_)\n",
    "        shape_variants[svc].append((name, vars_))\n",
    "\n",
    "reserved_site_cells: set[int] = set()     # клетки — территории\n",
    "reserved_service_cells: set[int] = set()  # клетки — корпуса (подмножество соответствующей территории)\n",
    "\n",
    "service_sites_geom = []\n",
    "service_sites_attrs = []\n",
    "service_polys_geom = []\n",
    "service_polys_attrs = []\n",
    "\n",
    "# ===== ЧАСТЬ 2/2 =====\n",
    "\n",
    "# ---------- ПРОВЕРКИ ЗАЗОРОВ ----------\n",
    "def _house_indices() -> np.ndarray:\n",
    "    return np.where(cells[\"is_building\"].fillna(False).to_numpy())[0]\n",
    "\n",
    "def _cheb_gap_ok_to_houses(candidate_idxs: list[int]) -> bool:\n",
    "    H = _house_indices()\n",
    "    if len(H) == 0 or len(candidate_idxs) == 0:\n",
    "        return True\n",
    "    d = _min_cheb_between_sets(cells, candidate_idxs, list(H))\n",
    "    return d >= GAP_TO_HOUSES_CHEB\n",
    "\n",
    "def _cheb_gap_ok_to_sites(candidate_idxs: list[int],\n",
    "                          placed_site_sets: list[list[int]],\n",
    "                          placed_sites_by_type: dict[str, list[list[int]]],\n",
    "                          svc: str) -> bool:\n",
    "    # Общий зазор со всеми участками (любой тип)\n",
    "    for S in placed_site_sets:\n",
    "        if _min_cheb_between_sets(cells, candidate_idxs, S) < GAP_BETWEEN_SITES_CHEB:\n",
    "            return False\n",
    "    # Усиленный зазор для участков того же типа\n",
    "    for S in placed_sites_by_type.get(svc, []):\n",
    "        if _min_cheb_between_sets(cells, candidate_idxs, S) < SAME_TYPE_SITE_GAP_CHEB:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# ---------- ВСПОМОГАТЕЛЬНО: сортировка паттернов под ориентацию core-окна ----------\n",
    "def _sort_variants_by_core_fit(variants: list[list[tuple[int,int]]], core_h: int, core_w: int) -> list[list[tuple[int,int]]]:\n",
    "    if core_h <= 0 or core_w <= 0:\n",
    "        return []\n",
    "    core_ar = core_w / core_h if core_h > 0 else 1.0\n",
    "    def dims(var):\n",
    "        vr = [dr for (dr,dc) in var]; vc = [dc for (dr,dc) in var]\n",
    "        h = max(vr) - min(vr) + 1\n",
    "        w = max(vc) - min(vc) + 1\n",
    "        return h, w\n",
    "    scored = []\n",
    "    for var in variants:\n",
    "        h, w = dims(var)\n",
    "        var_ar = w / h if h > 0 else 1.0\n",
    "        same_orient = int(not ((core_w >= core_h) ^ (w >= h)))  # 1 если ориентации совпали\n",
    "        ar_diff = abs(math.log(max(var_ar,1e-6)/max(core_ar,1e-6)))\n",
    "        scored.append((0 if same_orient else 1, ar_diff, h*w, var))\n",
    "    scored.sort(key=lambda t: (t[0], t[1], t[2]))\n",
    "    return [t[3] for t in scored]\n",
    "\n",
    "# ---------- КОРПУС ВНУТРИ ТЕРРИТОРИИ (core >= 1 клетка от границ) ----------\n",
    "def _try_place_service_inside_site(svc: str, zid: int, site_idxs: list[int],\n",
    "                                   site_id: str,\n",
    "                                   shape_variants: dict[str, list[tuple[str, list[list[tuple[int,int]]]]]],\n",
    "                                   reserved_service_cells: set[int],\n",
    "                                   rng: random.Random,\n",
    "                                   inner_margin_cells: int = INNER_MARGIN_CELLS) -> tuple[bool, list[int], str]:\n",
    "    site_set = set(site_idxs)\n",
    "    rvals = cells.loc[site_idxs, \"row_i\"].to_numpy()\n",
    "    cvals = cells.loc[site_idxs, \"col_j\"].to_numpy()\n",
    "    rmin, rmax = int(rvals.min()), int(rvals.max())\n",
    "    cmin, cmax = int(cvals.min()), int(cvals.max())\n",
    "\n",
    "    # Core-окно (эрозия на inner_margin_cells)\n",
    "    rmin_core = rmin + inner_margin_cells\n",
    "    rmax_core = rmax - inner_margin_cells\n",
    "    cmin_core = cmin + inner_margin_cells\n",
    "    cmax_core = cmax - inner_margin_cells\n",
    "    if (rmin_core > rmax_core) or (cmin_core > cmax_core):\n",
    "        return False, [], \"\"\n",
    "\n",
    "    core_h = rmax_core - rmin_core + 1\n",
    "    core_w = cmax_core - cmin_core + 1\n",
    "    cen_r = 0.5 * (rmin_core + rmax_core)\n",
    "    cen_c = 0.5 * (cmin_core + cmax_core)\n",
    "\n",
    "    for (pat_name, variants) in shape_variants.get(svc, []):\n",
    "        vars_iter = list(variants)\n",
    "        if RANDOMIZE_SERVICE_FORMS:\n",
    "            rng.shuffle(vars_iter)\n",
    "        vars_iter = _sort_variants_by_core_fit(vars_iter, core_h, core_w)\n",
    "\n",
    "        for var in vars_iter:\n",
    "            vr = [dr for (dr,dc) in var]; vc = [dc for (dr,dc) in var]\n",
    "            h, w = (max(vr)-min(vr)+1), (max(vc)-min(vc)+1)\n",
    "            if h > core_h or w > core_w:\n",
    "                continue\n",
    "\n",
    "            positions = [(r0, c0)\n",
    "                         for r0 in range(rmin_core, rmax_core - h + 2)\n",
    "                         for c0 in range(cmin_core, cmax_core - w + 2)]\n",
    "            positions.sort(key=lambda rc: (rc[0]-cen_r)**2 + (rc[1]-cen_c)**2)\n",
    "\n",
    "            for (r0, c0) in positions:\n",
    "                idxs = []\n",
    "                ok = True\n",
    "                for (dr, dc) in var:\n",
    "                    rr, cc = r0 + dr, c0 + dc\n",
    "                    idx = idx_by_rc.get((rr, cc))\n",
    "                    if (idx is None) or (idx in reserved_service_cells) or (idx not in site_set):\n",
    "                        ok = False; break\n",
    "                    idxs.append(idx)\n",
    "                if not ok:\n",
    "                    continue\n",
    "                return True, idxs, pat_name\n",
    "\n",
    "    return False, [], \"\"\n",
    "\n",
    "# ---------- ТЕРРИТОРИЯ + КОРПУС (внутри core) ДЛЯ iso>=L ----------\n",
    "def _try_place_site_and_service_in_zone_level(zid: int, svc: str, allowed_ids: list[int],\n",
    "                                              r_cen: float, c_cen: float,\n",
    "                                              placed_site_sets: list[list[int]],\n",
    "                                              placed_sites_by_type: dict[str, list[list[int]]],\n",
    "                                              rng: random.Random) -> bool:\n",
    "    if not allowed_ids:\n",
    "        return False\n",
    "\n",
    "    allowed_set = set(allowed_ids)\n",
    "    coord_to_idx = {(int(cells.at[i,\"row_i\"]), int(cells.at[i,\"col_j\"])): i for i in allowed_ids}\n",
    "    sub = cells.loc[allowed_ids, [\"row_i\",\"col_j\"]]\n",
    "    rmin, rmax = int(sub[\"row_i\"].min()), int(sub[\"row_i\"].max())\n",
    "    cmin, cmax = int(sub[\"col_j\"].min()), int(sub[\"col_j\"].max())\n",
    "\n",
    "    positions = _positions_from_center_or_edges(svc, rmin, rmax, cmin, cmax, r_cen, c_cen, invert=False)\n",
    "\n",
    "    service_variants = list(shape_variants.get(svc, []))\n",
    "    if RANDOMIZE_SERVICE_FORMS:\n",
    "        rng.shuffle(service_variants)\n",
    "\n",
    "    for (pat_name, _service_vars) in service_variants:\n",
    "        site_area_m2, capacity = _service_site_spec(svc, pat_name)\n",
    "        territory_variants = _territory_shape_variants(site_area_m2, CELL_SIZE_M)\n",
    "        if RANDOMIZE_SERVICE_FORMS:\n",
    "            rng.shuffle(territory_variants)\n",
    "\n",
    "        for (site_form_name, site_offsets) in territory_variants:\n",
    "            vrr = [dr for (dr,dc) in site_offsets]; vcc = [dc for (dr,dc) in site_offsets]\n",
    "            Hs, Ws = (max(vrr)-min(vrr)+1), (max(vcc)-min(vcc)+1)\n",
    "\n",
    "            for (r0, c0) in positions:\n",
    "                if r0 + Hs - 1 > rmax or c0 + Ws - 1 > cmax:\n",
    "                    continue\n",
    "\n",
    "                site_idxs = []\n",
    "                ok = True\n",
    "                for (dr, dc) in site_offsets:\n",
    "                    rr, cc = r0 + dr, c0 + dc\n",
    "                    idx = coord_to_idx.get((rr, cc))\n",
    "                    if (idx is None) or (idx in reserved_site_cells) or (idx in reserved_service_cells):\n",
    "                        ok = False; break\n",
    "                    if idx not in allowed_set:\n",
    "                        ok = False; break\n",
    "                    if cells.at[idx, \"is_building\"]:\n",
    "                        ok = False; break\n",
    "                    site_idxs.append(idx)\n",
    "                if not ok:\n",
    "                    continue\n",
    "\n",
    "                # зазоры: до домов, до любых участков, и усиленный до участков того же типа\n",
    "                if not _cheb_gap_ok_to_houses(site_idxs):\n",
    "                    continue\n",
    "                if not _cheb_gap_ok_to_sites(site_idxs, placed_site_sets, placed_sites_by_type, svc):\n",
    "                    continue\n",
    "\n",
    "                # корпус внутри core-окна участка\n",
    "                ok_svc, svc_cell_idxs, chosen_pat = _try_place_service_inside_site(\n",
    "                    svc, zid, site_idxs, site_id=\"__tmp__\",\n",
    "                    shape_variants=shape_variants,\n",
    "                    reserved_service_cells=reserved_service_cells,\n",
    "                    rng=rng,\n",
    "                    inner_margin_cells=INNER_MARGIN_CELLS\n",
    "                )\n",
    "                if not ok_svc:\n",
    "                    continue\n",
    "\n",
    "                # --- УСПЕХ: фиксируем участок и корпус ---\n",
    "                site_id = f\"SITE_{svc.upper()}_{str(len(service_sites_attrs)+1).zfill(4)}\"\n",
    "                service_id = f\"{svc.upper()}_{str(len(service_polys_attrs)+1).zfill(4)}\"\n",
    "\n",
    "                for idx in site_idxs:\n",
    "                    reserved_site_cells.add(idx)\n",
    "                    cells.loc[idx, \"is_service_site\"] = True\n",
    "                    cells.loc[idx, \"site_id\"] = site_id\n",
    "                    cells.loc[idx, \"service_site_type\"] = svc\n",
    "\n",
    "                for idx in svc_cell_idxs:\n",
    "                    reserved_service_cells.add(idx)\n",
    "                    cells.loc[idx, \"service\"] = svc\n",
    "\n",
    "                site_poly = _make_valid(unary_union([cells.geometry[i] for i in site_idxs]))\n",
    "                svc_poly  = _make_valid(unary_union([cells.geometry[i] for i in svc_cell_idxs]))\n",
    "\n",
    "                service_sites_geom.append(site_poly)\n",
    "                service_sites_attrs.append({\n",
    "                    \"site_id\": site_id,\n",
    "                    \"service\": svc,\n",
    "                    \"zone_id\": int(zid),\n",
    "                    \"site_form\": site_form_name,\n",
    "                    \"pattern_for_norms\": pat_name,\n",
    "                    \"site_cells\": int(len(site_idxs)),\n",
    "                    \"site_area_target_m2\": float(site_area_m2),\n",
    "                    \"site_area_actual_m2\": float(getattr(site_poly, \"area\", 0.0)),\n",
    "                    \"capacity\": int(capacity),\n",
    "                })\n",
    "\n",
    "                service_polys_geom.append(svc_poly)\n",
    "                service_polys_attrs.append({\n",
    "                    \"building_id\": service_id,\n",
    "                    \"site_id\": site_id,\n",
    "                    \"service\": svc,\n",
    "                    \"pattern\": chosen_pat,\n",
    "                    \"zone_id\": int(zid),\n",
    "                    \"n_cells\": int(len(svc_cell_idxs)),\n",
    "                    \"width_m\": float(CELL_SIZE_M),\n",
    "                })\n",
    "\n",
    "                placed_site_sets.append(site_idxs)\n",
    "                placed_sites_by_type.setdefault(svc, []).append(site_idxs)\n",
    "                svc_count_by_zone[zid][svc] = svc_count_by_zone.get(zid, {svc:0}).get(svc,0) + 1\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# ---------- FALLBACK: ВНЕ inside_iso ----------\n",
    "def _try_place_site_and_service_fallback_outside(zid: int, svc: str, outside_ids: list[int],\n",
    "                                                 r_cen: float, c_cen: float,\n",
    "                                                 placed_site_sets: list[list[int]],\n",
    "                                                 placed_sites_by_type: dict[str, list[list[int]]],\n",
    "                                                 rng: random.Random) -> bool:\n",
    "    if not outside_ids:\n",
    "        return False\n",
    "\n",
    "    allowed_ids = [i for i in outside_ids if (i not in reserved_site_cells) and (not cells.at[i,\"is_building\"])]\n",
    "    if not allowed_ids:\n",
    "        return False\n",
    "\n",
    "    allowed_set = set(allowed_ids)\n",
    "    coord_to_idx = {(int(cells.at[i,\"row_i\"]), int(cells.at[i,\"col_j\"])): i for i in allowed_ids}\n",
    "    sub = cells.loc[allowed_ids, [\"row_i\",\"col_j\"]]\n",
    "    rmin, rmax = int(sub[\"row_i\"].min()), int(sub[\"row_i\"].max())\n",
    "    cmin, cmax = int(sub[\"col_j\"].min()), int(sub[\"col_j\"].max())\n",
    "    positions = _positions_from_center_or_edges(svc, rmin, rmax, cmin, cmax, r_cen, c_cen, invert=False)\n",
    "\n",
    "    service_variants = list(shape_variants.get(svc, []))\n",
    "    if RANDOMIZE_SERVICE_FORMS:\n",
    "        rng.shuffle(service_variants)\n",
    "\n",
    "    for (pat_name, _service_vars) in service_variants:\n",
    "        site_area_m2, capacity = _service_site_spec(svc, pat_name)\n",
    "        min_cells = _min_site_cells_for_service_with_margin(svc, shape_variants, INNER_MARGIN_CELLS)\n",
    "        ncells = max(_site_cells_required(site_area_m2, CELL_SIZE_M), min_cells)\n",
    "        territory_variants = _rect_variants_for_cells(ncells, max_variants=12)\n",
    "        if RANDOMIZE_SERVICE_FORMS:\n",
    "            rng.shuffle(territory_variants)\n",
    "\n",
    "        for (site_form_name, site_offsets) in territory_variants:\n",
    "            vrr = [dr for (dr,dc) in site_offsets]; vcc = [dc for (dr,dc) in site_offsets]\n",
    "            Hs, Ws = (max(vrr)-min(vrr)+1), (max(vcc)-min(vcc)+1)\n",
    "\n",
    "            for (r0, c0) in positions:\n",
    "                if r0 + Hs - 1 > rmax or c0 + Ws - 1 > cmax:\n",
    "                    continue\n",
    "\n",
    "                site_idxs = []\n",
    "                ok = True\n",
    "                for (dr, dc) in site_offsets:\n",
    "                    rr, cc = r0 + dr, c0 + dc\n",
    "                    idx = coord_to_idx.get((rr, cc))\n",
    "                    if (idx is None) or (idx in reserved_site_cells) or (idx in reserved_service_cells):\n",
    "                        ok = False; break\n",
    "                    if idx not in allowed_set:\n",
    "                        ok = False; break\n",
    "                    if cells.at[idx, \"is_building\"]:\n",
    "                        ok = False; break\n",
    "                    site_idxs.append(idx)\n",
    "                if not ok:\n",
    "                    continue\n",
    "\n",
    "                if not _cheb_gap_ok_to_houses(site_idxs):\n",
    "                    continue\n",
    "                if not _cheb_gap_ok_to_sites(site_idxs, placed_site_sets, placed_sites_by_type, svc):\n",
    "                    continue\n",
    "\n",
    "                ok_svc, svc_cell_idxs, chosen_pat = _try_place_service_inside_site(\n",
    "                    svc, zid, site_idxs, site_id=\"__tmp__\",\n",
    "                    shape_variants=shape_variants,\n",
    "                    reserved_service_cells=reserved_service_cells,\n",
    "                    rng=rng,\n",
    "                    inner_margin_cells=INNER_MARGIN_CELLS\n",
    "                )\n",
    "                if not ok_svc:\n",
    "                    continue\n",
    "\n",
    "                # --- УСПЕХ: фиксируем участок и корпус ---\n",
    "                site_id = f\"SITE_{svc.upper()}_{str(len(service_sites_attrs)+1).zfill(4)}\"\n",
    "                service_id = f\"{svc.upper()}_{str(len(service_polys_attrs)+1).zfill(4)}\"\n",
    "\n",
    "                for idx in site_idxs:\n",
    "                    reserved_site_cells.add(idx)\n",
    "                    cells.loc[idx, \"is_service_site\"] = True\n",
    "                    cells.loc[idx, \"site_id\"] = site_id\n",
    "                    cells.loc[idx, \"service_site_type\"] = svc\n",
    "\n",
    "                for idx in svc_cell_idxs:\n",
    "                    reserved_service_cells.add(idx)\n",
    "                    cells.loc[idx, \"service\"] = svc\n",
    "\n",
    "                site_poly = _make_valid(unary_union([cells.geometry[i] for i in site_idxs]))\n",
    "                svc_poly  = _make_valid(unary_union([cells.geometry[i] for i in svc_cell_idxs]))\n",
    "\n",
    "                service_sites_geom.append(site_poly)\n",
    "                service_sites_attrs.append({\n",
    "                    \"site_id\": site_id,\n",
    "                    \"service\": svc,\n",
    "                    \"zone_id\": int(zid),\n",
    "                    \"site_form\": site_form_name,\n",
    "                    \"pattern_for_norms\": pat_name,\n",
    "                    \"site_cells\": int(len(site_idxs)),\n",
    "                    \"site_area_target_m2\": float(site_area_m2),\n",
    "                    \"site_area_actual_m2\": float(getattr(site_poly, \"area\", 0.0)),\n",
    "                    \"capacity\": int(capacity),\n",
    "                    \"fallback_outside\": True,\n",
    "                })\n",
    "\n",
    "                service_polys_geom.append(svc_poly)\n",
    "                service_polys_attrs.append({\n",
    "                    \"building_id\": service_id,\n",
    "                    \"site_id\": site_id,\n",
    "                    \"service\": svc,\n",
    "                    \"pattern\": chosen_pat,\n",
    "                    \"zone_id\": int(zid),\n",
    "                    \"n_cells\": int(len(svc_cell_idxs)),\n",
    "                    \"width_m\": float(CELL_SIZE_M),\n",
    "                    \"fallback_outside\": True,\n",
    "                })\n",
    "\n",
    "                placed_site_sets.append(site_idxs)\n",
    "                placed_sites_by_type.setdefault(svc, []).append(site_idxs)\n",
    "                svc_count_by_zone[zid][svc] = svc_count_by_zone.get(zid, {svc:0}).get(svc,0) + 1\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# ---------- ОСНОВНОЙ ЦИКЛ: РАУНД-РОБИН ПО ТИПАМ (по одному за проход) ----------\n",
    "placed_site_sets: list[list[int]] = []                         # глобальный список всех участков (для общего зазора)\n",
    "svc_order = [\"school\", \"kindergarten\", \"polyclinics\"]\n",
    "placed_sites_by_type: dict[str, list[list[int]]] = {s: [] for s in svc_order}  # НОВОЕ: для усиленного зазора 10 клеток\n",
    "\n",
    "for zid, meta in zone_groups.items():\n",
    "    r_cen, c_cen = meta[\"r_center\"], meta[\"c_center\"]\n",
    "    Lmax = meta[\"Lmax\"]\n",
    "    z_inside = meta[\"inside_ids\"]\n",
    "    z_outside = meta[\"outside_ids\"]\n",
    "\n",
    "    limits = {svc: MAX_SERVICES_PER_ZONE.get(svc, 0) for svc in svc_order}\n",
    "\n",
    "    # Крутимся, пока в этом квартале удаётся что-то поставить за один полный проход\n",
    "    while True:\n",
    "        progress = False\n",
    "        for svc in svc_order:\n",
    "            if svc_count_by_zone[zid][svc] >= limits[svc]:\n",
    "                continue\n",
    "\n",
    "            # Пытаемся поставить ровно ОДИН объект этого svc за цикл:\n",
    "            placed_here = False\n",
    "            for L in range(Lmax, -1, -1):\n",
    "                allowed_ids = [i for i in z_inside\n",
    "                               if (i not in reserved_site_cells)\n",
    "                               and (not cells.at[i,\"is_building\"])\n",
    "                               and pd.notna(cells.at[i, \"iso_level\"])\n",
    "                               and (int(cells.at[i,\"iso_level\"]) >= L)]\n",
    "                if not allowed_ids:\n",
    "                    continue\n",
    "                if _try_place_site_and_service_in_zone_level(\n",
    "                        zid, svc, allowed_ids, r_cen, c_cen,\n",
    "                        placed_site_sets, placed_sites_by_type, rng):\n",
    "                    placed_here = True\n",
    "                    break\n",
    "            if not placed_here and z_outside:\n",
    "                if _try_place_site_and_service_fallback_outside(\n",
    "                        zid, svc, z_outside, r_cen, c_cen,\n",
    "                        placed_site_sets, placed_sites_by_type, rng):\n",
    "                    placed_here = True\n",
    "\n",
    "            if placed_here:\n",
    "                progress = True  # За этот проход мы поставили ОДИН объект данного типа\n",
    "            # Идём к следующему типу, даже если можно было бы поставить ещё — «по одному за цикл»\n",
    "\n",
    "        if not progress:\n",
    "            break  # В этом квартале больше ничего не вставляется с учётом всех ограничений\n",
    "\n",
    "# ---------- СБОРКА ЖИЛЫХ ПОЛИГОНОВ ----------\n",
    "is_b = cells[\"is_building\"].to_numpy().astype(bool)\n",
    "\n",
    "diag_only_nodes = []\n",
    "for i in range(len(cells)):\n",
    "    if not is_b[i]: continue\n",
    "    side_in = any(is_b[j] for j in neighbors_side.get(i, []))\n",
    "    diag_in = any(is_b[j] for j in neighbors_diag.get(i, []))\n",
    "    if (not side_in) and diag_in:\n",
    "        diag_only_nodes.append(i)\n",
    "\n",
    "diag_adj = {i: [j for j in neighbors_diag.get(i, []) if is_b[j]] for i in range(len(cells))}\n",
    "diag_components = _components(diag_only_nodes, diag_adj)\n",
    "diag_components = [comp for comp in diag_components if len(comp) >= 2]\n",
    "\n",
    "cells[\"is_diag_only\"] = False\n",
    "for comp in diag_components:\n",
    "    for i in comp: cells.at[i, \"is_diag_only\"] = True\n",
    "\n",
    "records_geom, records_attrs = [], []\n",
    "\n",
    "try:\n",
    "    from shapely.geometry import CAP_STYLE, JOIN_STYLE\n",
    "    cap_style = CAP_STYLE.flat; join_style = JOIN_STYLE.mitre\n",
    "except Exception:\n",
    "    cap_style = 2; join_style = 2\n",
    "\n",
    "buf_dist = float(CELL_SIZE_M) / 2.0\n",
    "centroids = cells.geometry.centroid\n",
    "\n",
    "# Диагональные жилые → полоса-буфер\n",
    "for k, comp in enumerate(diag_components, start=1):\n",
    "    pts = np.array([[centroids[i].x, centroids[i].y] for i in comp], dtype=float)\n",
    "    if len(pts) < 2: continue\n",
    "    order = _pca_order(pts)\n",
    "    ordered_pts = pts[order]\n",
    "    ordered_pts = ordered_pts[np.concatenate(([True], np.any(np.diff(ordered_pts, axis=0) != 0, axis=1)))]\n",
    "    if len(ordered_pts) < 2: continue\n",
    "    line = LineString(ordered_pts)\n",
    "    poly = line.buffer(buf_dist, cap_style=cap_style, join_style=join_style)\n",
    "    records_geom.append(_make_valid(poly))\n",
    "    records_attrs.append({\n",
    "        \"building_id\": f\"D{str(k).zfill(5)}\",\n",
    "        \"type\": \"diag_buffer\",\n",
    "        \"service\": \"living_house\",\n",
    "        \"n_cells\": int(len(comp)),\n",
    "        \"width_m\": float(CELL_SIZE_M),\n",
    "    })\n",
    "\n",
    "# Простые жилые клетки\n",
    "simple_ids = [i for i in range(len(cells))\n",
    "              if cells.at[i,\"is_building\"] and not cells.at[i,\"is_diag_only\"]]\n",
    "for i in simple_ids:\n",
    "    records_geom.append(_make_valid(cells.geometry[i]))\n",
    "    records_attrs.append({\n",
    "        \"building_id\": f\"C{str(i).zfill(6)}\",\n",
    "        \"type\": \"cell\",\n",
    "        \"service\": \"living_house\",\n",
    "        \"n_cells\": 1,\n",
    "        \"width_m\": float(CELL_SIZE_M),\n",
    "        \"row_i\": int(cells.at[i, \"row_i\"]),\n",
    "        \"col_j\": int(cells.at[i, \"col_j\"]),\n",
    "        zone_id_col: int(cells.at[i, zone_id_col]) if not pd.isna(cells.at[i, zone_id_col]) else None,\n",
    "    })\n",
    "\n",
    "# Добавляем корпуса сервисов\n",
    "records_geom.extend(service_polys_geom)\n",
    "records_attrs.extend(service_polys_attrs)\n",
    "\n",
    "buildings_rects = gpd.GeoDataFrame(records_attrs, geometry=records_geom, crs=cells.crs).reset_index(drop=True)\n",
    "\n",
    "# ---------- MERGE без склейки разных service ----------\n",
    "left = buildings_rects[[\"geometry\"]].reset_index().rename(columns={\"index\": \"i\"})\n",
    "right = buildings_rects[[\"geometry\"]].reset_index().rename(columns={\"index\": \"j\"})\n",
    "pairs = _sjoin_generic(left, right, predicate=MERGE_PREDICATE)\n",
    "pairs = pairs[(pairs[\"i\"] != pairs[\"j\"]) & pairs[\"j\"].notna()].copy()\n",
    "pairs[\"j\"] = pairs[\"j\"].astype(int)\n",
    "\n",
    "svc_vals = buildings_rects.get(\"service\", pd.Series([\"living_house\"]*len(buildings_rects))).astype(object).tolist()\n",
    "def _same_group(i,j):\n",
    "    si, sj = svc_vals[i], svc_vals[j]\n",
    "    return si == sj\n",
    "\n",
    "pairs = pairs[pairs.apply(lambda r: _same_group(int(r[\"i\"]), int(r[\"j\"])), axis=1)]\n",
    "\n",
    "adj = {i: [] for i in range(len(buildings_rects))}\n",
    "for a, b in pairs[[\"i\", \"j\"]].itertuples(index=False):\n",
    "    a = int(a); b = int(b)\n",
    "    adj[a].append(b); adj[b].append(a)\n",
    "\n",
    "groups = _components(list(adj.keys()), adj)\n",
    "\n",
    "merged_geoms = []; merged_attrs = []\n",
    "for gid, comp in enumerate(groups):\n",
    "    geoms = buildings_rects.geometry.iloc[comp].tolist()\n",
    "    if MERGE_FIX_EPS and MERGE_FIX_EPS > 0:\n",
    "        u = unary_union([_make_valid(g.buffer(MERGE_FIX_EPS)) for g in geoms]).buffer(-MERGE_FIX_EPS)\n",
    "    else:\n",
    "        u = unary_union([_make_valid(g) for g in geoms])\n",
    "    comp_svc = list({svc_vals[i] for i in comp})\n",
    "    merged_service = comp_svc[0] if len(comp_svc) == 1 else \"mixed\"\n",
    "    types = \",\".join(sorted(set(buildings_rects.loc[comp, \"type\"].astype(str).tolist())))\n",
    "    zid_mode = None\n",
    "    if zone_id_col in buildings_rects.columns:\n",
    "        zids = buildings_rects.loc[comp, zone_id_col].dropna().astype(int)\n",
    "        if len(zids) > 0: zid_mode = int(zids.value_counts().index[0])\n",
    "    merged_geoms.append(_make_valid(u))\n",
    "    merged_attrs.append({\n",
    "        \"group_id\": int(gid),\n",
    "        \"n_members\": int(len(comp)),\n",
    "        \"n_cells_sum\": int(np.nansum(buildings_rects.loc[comp, \"n_cells\"].values)) if \"n_cells\" in buildings_rects else None,\n",
    "        \"types\": types,\n",
    "        \"service\": merged_service,\n",
    "        zone_id_col: zid_mode,\n",
    "    })\n",
    "\n",
    "buildings_merged = gpd.GeoDataFrame(merged_attrs, geometry=merged_geoms, crs=cells.crs).reset_index(drop=True)\n",
    "buildings_merged = buildings_merged[buildings_merged.area > CELL_SIZE_M*CELL_SIZE_M]\n",
    "\n",
    "# ---------- МЕТРИКИ (по участкам сервисов) ----------\n",
    "service_sites_gdf = gpd.GeoDataFrame(service_sites_attrs, geometry=service_sites_geom, crs=cells.crs).reset_index(drop=True)\n",
    "\n",
    "metrics_rows = []\n",
    "if len(service_sites_gdf) > 0:\n",
    "    service_sites_gdf[\"centroid\"] = service_sites_gdf.geometry.representative_point()\n",
    "    for (zid, svc), sub in service_sites_gdf.groupby([zone_id_col, \"service\"], dropna=True):\n",
    "        pts = list(sub[\"centroid\"])\n",
    "        n = len(pts)\n",
    "        if n == 1:\n",
    "            min_nn = float(\"inf\"); mean_nn = float(\"inf\"); score = 1.0\n",
    "        else:\n",
    "            dmat = np.zeros((n, n), dtype=float)\n",
    "            for i in range(n):\n",
    "                for j in range(i+1, n):\n",
    "                    d = pts[i].distance(pts[j])\n",
    "                    dmat[i,j] = dmat[j,i] = d\n",
    "            nn = np.min(np.where(dmat==0, np.inf, dmat), axis=1)\n",
    "            min_nn = float(np.min(nn)); mean_nn = float(np.mean(nn))\n",
    "            score = float(mean_nn / (CELL_SIZE_M))\n",
    "        metrics_rows.append({\n",
    "            zone_id_col: int(zid),\n",
    "            \"service\": svc,\n",
    "            \"sites_count\": int(n),\n",
    "            \"min_nn_m\": None if math.isinf(min_nn) else float(min_nn),\n",
    "            \"mean_nn_m\": None if math.isinf(mean_nn) else float(mean_nn),\n",
    "            \"uniformity_score\": score,\n",
    "        })\n",
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "if len(metrics_df) > 0:\n",
    "    metrics_df.to_csv(OUT_SVC_METRICS, index=False)\n",
    "\n",
    "# ---------- Финальные статусы в клетках ----------\n",
    "cells.loc[cells[\"is_building\"].fillna(False), \"service\"] = cells.loc[cells[\"is_building\"].fillna(False), \"service\"].fillna(\"living_house\")\n",
    "\n",
    "# ---------- Сохранение ----------\n",
    "cells_out = cells.copy()\n",
    "cells_out.to_file(OUT_CELLS, driver=\"GeoJSON\")\n",
    "buildings_rects.to_file(OUT_RECTS, driver=\"GeoJSON\")\n",
    "buildings_merged.to_file(OUT_MERGED, driver=\"GeoJSON\")\n",
    "if len(service_sites_gdf) > 0:\n",
    "    service_sites_gdf.drop(columns=['centroid'], inplace=True)\n",
    "    service_sites_gdf.to_file(OUT_SVC_SITES, driver=\"GeoJSON\")\n",
    "\n",
    "svc_rects = buildings_rects[buildings_rects.get(\"service\").isin([\"school\",\"kindergarten\",\"polyclinics\"])]\n",
    "\n",
    "print(\n",
    "    f\"OK → {OUT_CELLS.name}  (клеток: {len(cells_out)}, жилых: {int(cells_out['is_building'].sum())}, diag-only: {int(cells_out['is_diag_only'].sum())})\\n\"\n",
    "    f\"OK → {OUT_RECTS.name}  (элементов: {len(buildings_rects)}, сервис-корпусов: {len(svc_rects)})\\n\"\n",
    "    f\"OK → {OUT_MERGED.name} (полигонов: {len(buildings_merged)}, \"\n",
    "    f\"schools: {int((buildings_merged.get('service')=='school').sum())}, \"\n",
    "    f\"kindergartens: {int((buildings_merged.get('service')=='kindergarten').sum())}, \"\n",
    "    f\"polyclinics: {int((buildings_merged.get('service')=='polyclinics').sum())}, \"\n",
    "    f\"living_house: {int((buildings_merged.get('service')=='living_house').sum())})\\n\"\n",
    "    f\"Uniformity CSV: {OUT_SVC_METRICS.name} (по УЧАСТКАМ)\\n\"\n",
    "    f\"Service sites: {OUT_SVC_SITES.name} (участков: {len(service_sites_gdf)})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK → buildings_clustered_buildings_merged_with_floors_living.geojson (floors_count для всех; living_area только в зонах с target)\n",
      "OK → buildings_clustered_buildings_merged_living_summary.csv (сводка по зонам с target)\n",
      "Всего объектов: 253, жилых домов: 246, средний K по зонам (если есть): 0.500\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Расчёт этажности и распределение жилой площади по жилым домам\n",
    "# Правила:\n",
    "# 1) floors_count = round(area_m2 / 100), но: floors_count ∈ [1, max_floor(zone)]\n",
    "# 2) Жилая площадь в доме: living_area = K * area_m2 * floors_count, где K ∈ [0.5, 0.75]\n",
    "# 3) Целевую площадь target_living_area по зоне распределяем с приоритетом к границам квартала\n",
    "#    (вес = 1 / distance_to_zone_boundary), с соблюдением K-ограничений.\n",
    "# ДОПОЛНИТЕЛЬНО:\n",
    "# 4) Жилая площадь вычисляется ТОЛЬКО для зон, где явно задан target_living_area; для остальных living_area=0, K=NaN.\n",
    "# 5) Этажность сервисов фиксирована: kindergarten=2, school=3, polyclinics=4 (и не превышает max_floor).\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# ---------------- ПОЛЬЗОВАТЕЛЬСКИЕ ВХОДЫ ----------------\n",
    "BUILDINGS_PATH = Path(\"/root/globalmapper_learning/out_2/buildings_clustered_buildings_merged.geojson\")\n",
    "ZONES_PATH     = Path(\"/root/globalmapper_learning/zones.geojson\")\n",
    "\n",
    "# Автоподхват из /mnt/data при наличии\n",
    "if Path(\"/mnt/data/buildings_merged.geojson\").exists():\n",
    "    BUILDINGS_PATH = Path(\"/mnt/data/buildings_merged.geojson\")\n",
    "if Path(\"/mnt/data/zones.geojson\").exists():\n",
    "    ZONES_PATH = Path(\"/mnt/data/zones.geojson\")\n",
    "\n",
    "# Параметры по зонам:\n",
    "# Вариант А: по zone_id\n",
    "ZONE_PARAMS_BY_ID = {\n",
    "    # пример: 101: {\"target_living_area\": 120000.0, \"max_floor\": 12},\n",
    "}\n",
    "# Вариант Б: по названию зоны (поле \"zone\" или аналог)\n",
    "ZONE_PARAMS_BY_NAME = {\n",
    "    \"residential\": {\"target_living_area\": 20000.0, \"max_floor\": 9},\n",
    "    \"industrial\":  {\"target_living_area\": 0.0,     \"max_floor\": 5},\n",
    "    \"business\":    {\"target_living_area\": 0.0,     \"max_floor\": 15},\n",
    "}\n",
    "\n",
    "# Фиксированные этажности сервисов\n",
    "SERVICE_FIXED_FLOORS = {\n",
    "    \"kindergarten\": 2,\n",
    "    \"school\": 3,\n",
    "    \"polyclinics\": 4,\n",
    "}\n",
    "\n",
    "# ---------------- УТИЛИТЫ ----------------\n",
    "\n",
    "def to_metric_crs(gdf: gpd.GeoDataFrame, like: gpd.GeoDataFrame | None = None, fallback_epsg: int = 3857) -> gpd.GeoDataFrame:\n",
    "    if like is not None and like.crs is not None:\n",
    "        return gdf.to_crs(like.crs)\n",
    "    if gdf.crs is None:\n",
    "        return gdf.set_crs(epsg=fallback_epsg, allow_override=True)\n",
    "    if getattr(gdf.crs, \"is_projected\", None) is True:\n",
    "        return gdf\n",
    "    return gdf.to_crs(epsg=fallback_epsg)\n",
    "\n",
    "def zone_cols(zones: gpd.GeoDataFrame) -> tuple[str, str]:\n",
    "    zid = \"zone_id\" if \"zone_id\" in zones.columns else (\"id\" if \"id\" in zones.columns else \"ZONE_ID\")\n",
    "    if zid not in zones.columns:\n",
    "        zones[zid] = np.arange(len(zones))\n",
    "    zname = \"zone\"\n",
    "    if zname not in zones.columns:\n",
    "        for alt in [\"zone_name\", \"zone_type\", \"functional_zone_type_name\"]:\n",
    "            if alt in zones.columns:\n",
    "                zname = alt; break\n",
    "        else:\n",
    "            zones[\"zone\"] = \"unknown\"; zname = \"zone\"\n",
    "    return zid, zname\n",
    "\n",
    "def round_int(x: float) -> int:\n",
    "    return int(np.floor(x + 0.5))\n",
    "\n",
    "def waterfill_with_caps(weights: np.ndarray, caps: np.ndarray, demand: float, eps: float = 1e-9) -> np.ndarray:\n",
    "    n = len(weights)\n",
    "    x = np.zeros(n, dtype=float)\n",
    "    remain = np.arange(n)\n",
    "    D = float(max(demand, 0.0))\n",
    "    w = weights.copy().astype(float)\n",
    "    w[w < 0] = 0.0\n",
    "    while len(remain) > 0 and D > eps:\n",
    "        sw = float(w[remain].sum())\n",
    "        if sw <= eps:\n",
    "            break\n",
    "        inc = np.zeros_like(x)\n",
    "        for i in remain:\n",
    "            quota = D * (w[i] / sw)\n",
    "            inc[i] = min(quota, caps[i] - x[i])\n",
    "        inc_sum = float(inc[remain].sum())\n",
    "        if inc_sum <= eps:\n",
    "            break\n",
    "        x += inc\n",
    "        D -= inc_sum\n",
    "        remain = np.array([i for i in remain if (caps[i] - x[i]) > eps], dtype=int)\n",
    "    return x\n",
    "\n",
    "# ---------------- ЗАГРУЗКА ----------------\n",
    "buildings = gpd.read_file(BUILDINGS_PATH)\n",
    "zones = gpd.read_file(ZONES_PATH)\n",
    "zones = to_metric_crs(zones, like=buildings)\n",
    "\n",
    "zid_col, zname_col = zone_cols(zones)\n",
    "\n",
    "# (Пере)назначаем зону, если её нет или есть пропуски\n",
    "need_zone_join = (zid_col not in buildings.columns) or buildings[zid_col].isna().any()\n",
    "if need_zone_join:\n",
    "    cent = buildings.geometry.representative_point()\n",
    "    j = gpd.sjoin(\n",
    "        gpd.GeoDataFrame({\"i\": np.arange(len(buildings))}, geometry=cent, crs=buildings.crs),\n",
    "        zones[[zid_col, zname_col, \"geometry\"]],\n",
    "        how=\"left\", predicate=\"within\"\n",
    "    ).drop_duplicates(\"i\").set_index(\"i\")[[zid_col, zname_col]]\n",
    "    buildings = buildings.drop(columns=[zid_col, zname_col], errors=\"ignore\").join(j, how=\"left\")\n",
    "\n",
    "# нормализуем имя зоны\n",
    "buildings[zname_col] = buildings[zname_col].astype(str).str.lower().str.strip()\n",
    "buildings = to_metric_crs(buildings, like=zones)\n",
    "\n",
    "# Маски по типу\n",
    "service_series = buildings.get(\"service\").astype(str).str.lower()\n",
    "is_living  = service_series.eq(\"living_house\")\n",
    "is_school  = service_series.eq(\"school\")\n",
    "is_kinderg = service_series.eq(\"kindergarten\")\n",
    "is_poly    = service_series.eq(\"polyclinics\")\n",
    "\n",
    "houses = buildings.copy()  # будем писать туда новые колонки для всех объектов\n",
    "\n",
    "# Геометрическая площадь\n",
    "houses[\"area_m2\"] = houses.geometry.area.astype(float)\n",
    "\n",
    "# ---------------- ПАРАМЕТРЫ ЗОН: max_floor и наличие target ----------------\n",
    "def resolve_zone_params(row) -> tuple[float, int]:\n",
    "    zid = row.get(zid_col)\n",
    "    zname = row.get(zname_col)\n",
    "    targ = None; mf = None\n",
    "    if pd.notna(zid) and int(zid) in ZONE_PARAMS_BY_ID:\n",
    "        p = ZONE_PARAMS_BY_ID[int(zid)]\n",
    "        targ = p.get(\"target_living_area\")\n",
    "        mf   = p.get(\"max_floor\")\n",
    "    if (targ is None or mf is None) and pd.notna(zname):\n",
    "        p = ZONE_PARAMS_BY_NAME.get(str(zname).lower())\n",
    "        if p:\n",
    "            if targ is None: targ = p.get(\"target_living_area\")\n",
    "            if mf   is None: mf   = p.get(\"max_floor\")\n",
    "    if mf is None: mf = 9  # дефолтная верхняя планка\n",
    "    return (float(targ) if targ is not None else np.nan), int(mf)\n",
    "\n",
    "params = houses.apply(resolve_zone_params, axis=1, result_type=\"expand\")\n",
    "houses[\"target_zone_area\"], houses[\"max_floor_zone\"] = params[0].values, params[1].values\n",
    "\n",
    "# ---------------- ЭТАЖНОСТЬ ----------------\n",
    "# 1) ЖИЛЫЕ: floors = round(area/100), clip [1, max_floor_zone]\n",
    "floors_living = np.maximum(1, np.minimum(\n",
    "    houses.loc[is_living, \"max_floor_zone\"].astype(int).values,\n",
    "    np.vectorize(round_int)(houses.loc[is_living, \"area_m2\"].values / 100.0)\n",
    "))\n",
    "houses.loc[is_living, \"floors_count\"] = floors_living\n",
    "\n",
    "# 2) СЕРВИСЫ: фиксированные этажности (и клип по max_floor_zone)\n",
    "for svc_name, fixed in SERVICE_FIXED_FLOORS.items():\n",
    "    m = service_series.eq(svc_name)\n",
    "    if m.any():\n",
    "        maxf = houses.loc[m, \"max_floor_zone\"].astype(int)\n",
    "        houses.loc[m, \"floors_count\"] = np.minimum(int(fixed), maxf).astype(int)\n",
    "\n",
    "# Прочим (если есть) ничего не задаём; приведём тип\n",
    "houses[\"floors_count\"] = pd.to_numeric(houses[\"floors_count\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# ---------------- РАСПРЕДЕЛЕНИЕ ЖИЛОЙ ПЛОЩАДИ ТОЛЬКО ПО ЗОНАМ С TARGET ----------------\n",
    "# Для сервисов living_area=0, K=NaN всегда.\n",
    "houses[\"K\"] = np.nan\n",
    "houses[\"living_area\"] = 0.0  # по умолчанию 0 (и для зон без target)\n",
    "\n",
    "# Границы зон для весов\n",
    "zones[\"_boundary\"] = zones.geometry.boundary\n",
    "\n",
    "# Группируем только жилые, только по непустому zone_id\n",
    "valid_living = houses[is_living & houses[zid_col].notna()].copy()\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "for zid, sub in valid_living.groupby(valid_living[zid_col].astype(int)):\n",
    "    zid_int = int(zid)\n",
    "    Z = zones.loc[zones[zid_col] == zid_int]\n",
    "    if len(Z) == 0:\n",
    "        continue\n",
    "\n",
    "    # Целевая площадь для этой зоны\n",
    "    targ = sub[\"target_zone_area\"].dropna().iloc[0] if sub[\"target_zone_area\"].notna().any() else np.nan\n",
    "\n",
    "    if np.isnan(targ) or targ <= 0:\n",
    "        # ЯВНО: нет таргета → оставляем living_area=0 и K=NaN\n",
    "        houses.loc[sub.index, \"_alloc_status\"] = \"no_target → living=0\"\n",
    "        summary_rows.append({\n",
    "            \"zone_id\": zid_int,\n",
    "            \"target_requested\": float(targ) if not np.isnan(targ) else None,\n",
    "            \"target_used\": 0.0,\n",
    "            \"cap_min\": float((0.5 * sub[\"area_m2\"] * sub[\"floors_count\"]).sum()),\n",
    "            \"cap_max\": float((0.75 * sub[\"area_m2\"] * sub[\"floors_count\"]).sum()),\n",
    "            \"n_buildings\": int(len(sub)),\n",
    "            \"mean_K\": np.nan,\n",
    "            \"sum_living_area\": 0.0,\n",
    "            \"status\": \"no_target\",\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Капасити по K\n",
    "    cap_min = 0.5 * sub[\"area_m2\"] * sub[\"floors_count\"]\n",
    "    cap_max = 0.75 * sub[\"area_m2\"] * sub[\"floors_count\"]\n",
    "    cap_min_tot = float(cap_min.sum())\n",
    "    cap_max_tot = float(cap_max.sum())\n",
    "\n",
    "    # T в допустимых пределах (чтобы K остался в [0.5,0.75])\n",
    "    T = float(np.clip(targ, cap_min_tot, cap_max_tot))\n",
    "\n",
    "    # Веса: ближе к границе — больше\n",
    "    boundary = unary_union(list(Z[\"_boundary\"].values))\n",
    "    dists = sub.geometry.representative_point().distance(boundary).astype(float).values\n",
    "    weights = 1.0 / (1e-6 + dists)\n",
    "    if not np.isfinite(weights).any() or weights.sum() == 0.0:\n",
    "        weights = np.ones_like(dists, dtype=float)\n",
    "\n",
    "    deltas = (cap_max - cap_min).astype(float).values\n",
    "    D = T - cap_min_tot\n",
    "    x = waterfill_with_caps(weights, deltas, D)\n",
    "\n",
    "    living = cap_min.values + x\n",
    "    denom = (sub[\"area_m2\"].values * sub[\"floors_count\"].values)\n",
    "    K = np.divide(living, denom, out=np.zeros_like(living), where=denom > 0)\n",
    "    K = np.clip(K, 0.5, 0.75)\n",
    "\n",
    "    houses.loc[sub.index, \"K\"] = K\n",
    "    houses.loc[sub.index, \"living_area\"] = living\n",
    "    status = f\"T_used={T:.2f}; cap_min={cap_min_tot:.2f}; cap_max={cap_max_tot:.2f}\"\n",
    "    houses.loc[sub.index, \"_alloc_status\"] = status\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"zone_id\": zid_int,\n",
    "        \"target_requested\": float(targ),\n",
    "        \"target_used\": float(T),\n",
    "        \"cap_min\": cap_min_tot,\n",
    "        \"cap_max\": cap_max_tot,\n",
    "        \"n_buildings\": int(len(sub)),\n",
    "        \"mean_K\": float(np.mean(K)) if len(K) else np.nan,\n",
    "        \"sum_living_area\": float(np.sum(living)),\n",
    "        \"status\": status,\n",
    "    })\n",
    "\n",
    "# Для сервисов — статус\n",
    "houses.loc[is_school | is_kinderg | is_poly, \"_alloc_status\"] = houses.loc[is_school | is_kinderg | is_poly, \"_alloc_status\"].fillna(\"service → living=0\")\n",
    "\n",
    "# Собираем сводку\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# ---------------- ВЫВОД ----------------\n",
    "OUT_GEO = BUILDINGS_PATH.with_name(f\"{BUILDINGS_PATH.stem}_with_floors_living.geojson\")\n",
    "OUT_CSV = BUILDINGS_PATH.with_name(f\"{BUILDINGS_PATH.stem}_living_summary.csv\")\n",
    "\n",
    "# Чистим тех.поля\n",
    "if \"_boundary\" in zones.columns:\n",
    "    zones = zones.drop(columns=[\"_boundary\"])\n",
    "\n",
    "houses.to_file(OUT_GEO, driver=\"GeoJSON\")\n",
    "summary_df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\n",
    "    f\"OK → {OUT_GEO.name} (floors_count для всех; living_area только в зонах с target)\\n\"\n",
    "    f\"OK → {OUT_CSV.name} (сводка по зонам с target)\\n\"\n",
    "    f\"Всего объектов: {len(houses)}, жилых домов: {int(is_living.sum())}, \"\n",
    "    f\"средний K по зонам (если есть): {summary_df['mean_K'].mean(skipna=True) if len(summary_df)>0 else float('nan'):.3f}\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globalmaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
